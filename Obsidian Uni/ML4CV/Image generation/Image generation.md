*Instead of approximating functions, Image Generation aims to generate plausible new dataset samples, by learning the actual distribution*

## Latent space
Since images are high dimensional, generated by complex physical processes, we aim to learn a high level representation in a low dimensional space (latent space).

![[Pasted image 20240213164437.png]]
For instance,  facial expressions are governed by the change of 42 facial muscles. Only learning their position as a **latent vector** of size 42 is much easier than learning the distribution of all the pixels in the image.
![[Pasted image 20240213164836.png]]
To generate an image then, latent variables are sampled from a random distribution, and "made real" by passing through a neural network that translates the latent variable to real images following what it has learned.
Real images lies on a low dimensional manifold space (the majority of the possibilities are just random noise).
## Properties of a good generative model
- **Efficient sampling:** Generating samples from the model should be computationally inexpensive and take advantage of the parallelism of modern hardware. 
- **High-quality sampling:** The samples should be indistinguishable from the real data with which the model was trained. 
- **Coverage:** Samples should represent the entire training distribution. It is insufficient to generate samples that all look like a subset of the training examples. 
- **Well-behaved latent space:** Every latent variable z corresponds to a plausible data example x. Smooth changes in z correspond to smooth changes in x. 
- **Disentangled latent space:** Manipulating each dimension of z should correspond to changing an interpretable property of the data. For example, in a model of language, it might change the topic, tense, or verbosity. 
- **Efficient likelihood computation:** If the model is probabilistic, we would like to be able to calculate the probability of new examples efficiently and accurately.
![[Pasted image 20240213172922.png]]
There are no models that follow all those requisites, thus choosing the right one depends on the intended usage.
# Metrics
### Self-information and Entropy
Given the probability mass function P(x) of an event x, the self information is defined as:
$$I(x)=-log_{b}P(x)=log_{b}\frac{1}{P(X)}$$
And computes the *level of "surprise"* of an outcome. 
The **Information Entropy** instead is the expected value of the self information (of all possible events.
$$ H(p(\cdot))=E_{x}[.logp(\cdot)]=-\sum\limits_{x \in X} p(x)log(p(x))$$
- **Low Entropy** = deterministic process
- **High Entropy** = outcomes are difficult to predict
### Kullback-Leibler divergence (KL div)
Measures statistical distances over Entropy scores
$$D_{KL}(p||q)=E_x[log(p(x))-log((q(x)))]=E_{x}[log\frac{p(x)}{q(x)}]$$
- Asymmetric
- assigns high distances when $q(x)=0 \neq p(x)$ 
- Not usable as a metric
### Jensen-Shannon divergence (JS div)
adapts the [[#Kullback-Leibler divergence (KL div)]] to obtain symmetric and bounded distances:
![[Pasted image 20240213171952.png]]
- non-negative and bounded: $0 \le D_{JS} \le log_{b}2$
- Symmetric, respects triangle inequality
- **Usable metric**
### Inception score
A good generator should generate images which can be classified with high confidence by a pre-trained classifier on the same train dataset of the generator, i.e. p(class|generated img) should have **low entropy**
![[Pasted image 20240213173218.png]]
It should also generate all the possible images for all the classes handled by the classifier (good coverage), i.e. p(y) should have high entropy
![[Pasted image 20240213173629.png]]
Must balance between confidence and coverage!
The final Inception Score is defined as:
$$IS=exp(E_{x~p_{gen}(x)}[D_{KL}(p_{cls}(y|x)||p(y))])$$
**LIMITS:**
- needs large sample size 
- sensitive to classifier performance
- does not measure diversity within a class
### Earth mover's distance (EMD)
Alternative way to KL and JS divergence to express distances between distributions.
Amount of "work" to transform a distribution into the other (depending on how much mass we have to move)
![[Pasted image 20240213174757.png]]
### FrÃ©chet Inception Distance (FID)
Scores generative models by comparing the distributions of generated samples and real samples.
The comparison happens
- by embedding images using a pretrained [[Inception]] v-3 (no classification head)
- assuming the distributions as multi-variate gaussians
![[Pasted image 20240213175154.png]]
- The comparison accounts for realism and diversity within classes
- Sensitive to clasifier performance
- does not distinguish between realism and diversity
### Manifold precision/recall
To **disentangle realism and diversity**, we want to estimate the overlap between real data manifold and model (generated) manifold
- **precision** is the fraction of generated samples that fall in the real data manifold -> realism
- **recall** is the fraction of real data that fall into the model manifold -> diversity/coverage
![[Pasted image 20240213175537.png]]