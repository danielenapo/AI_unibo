{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dn6TLXlp6-sy"
      },
      "source": [
        "# Computer Vision and Image Processing - Lab Session 4\n",
        "\n",
        "Content:\n",
        "1. Introduction to Pytorch (from University of Amsterdam https://uvadlc.github.io)\n",
        "2. Neural Networks with pytorch\n",
        "3. Training loop\n",
        "\n",
        "Contacts:\n",
        "\n",
        "- Prof: Giuseppe Lisanti  (giuseppe.lisanti@unibo.it)\n",
        "- Prof: Samuele Salti  (samuele.salti@unibo.it)\n",
        "- Tutor: Adriano Cardace (adriano.cardace2@unibo.it)\n",
        "\n",
        "Course:\n",
        "\n",
        "- Website and notebooks will be available at https://virtuale.unibo.it"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Dependencies"
      ],
      "metadata": {
        "id": "XwNURhm8fhOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import random\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tqdm.notebook import tqdm\n",
        "import time"
      ],
      "metadata": {
        "id": "BVQZKvyufiKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Runtime Settings\n",
        "\n",
        "For this hands-on session and the next one, we are going to train on GPUs. To request a GPU for you virtual machine in Colab, you should change the Runtime settings. \n",
        "\n",
        "![nll](https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/uc14.png)"
      ],
      "metadata": {
        "id": "RLqo3_PHf0oE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Basics of PyTorch\n",
        "\n",
        "We will start with reviewing the very basic concepts of PyTorch. As a prerequisite, we recommend to be familiar with the `numpy` package as most machine learning frameworks are based on very similar concepts. If you are not familiar with numpy yet, don't worry: here is a [tutorial](https://numpy.org/devdocs/user/quickstart.html) to go through. \n",
        "\n",
        "So, let's start with importing PyTorch. The package is called `torch`, based on its original framework [Torch](http://torch.ch/). As a first step, we can check its version:"
      ],
      "metadata": {
        "id": "H0-AgE93gCN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"Using torch\", torch.__version__)"
      ],
      "metadata": {
        "id": "QC29pQZtfzoX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reproducibility\n",
        "When **developing and debugging** Neural Networks is desirable to have a deterministic behaviour. For this reason, we are going to disable all the sources of randomness. Please note that completely reproducible results are not guaranteed across PyTorch releases, individual commits or different platforms. You can find more detailed information at this [page](https://pytorch.org/docs/stable/notes/randomness.html).\n",
        "Please note that the flag `cudnn.benchmark = False` disable the auto-tuner that selects the optimal set of algorithms for your hardware and usually leads to slower runtime. "
      ],
      "metadata": {
        "id": "dgXBvsGKfuW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fix_random(seed: int) -> None:\n",
        "    \"\"\"Fix all the possible sources of randomness.\n",
        "\n",
        "    Args:\n",
        "        seed: the seed to use. \n",
        "    \"\"\"\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    \n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True        \n",
        "\n",
        "fix_random(42)"
      ],
      "metadata": {
        "id": "aA2TAJhHfpff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intro to Pytorch!\n"
      ],
      "metadata": {
        "id": "mFEQCaKNjeja"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensors\n",
        "\n",
        "Tensors are the PyTorch equivalent to Numpy arrays, with the addition to also have support for GPU acceleration (more on that later).\n",
        "The name \"tensor\" is a generalization of concepts you already know. For instance, a vector is a 1-D tensor, and a matrix a 2-D tensor. When working with neural networks, we will use tensors of various shapes and number of dimensions.\n",
        "\n",
        "Most common functions you know from numpy can be used on tensors as well. Actually, since numpy arrays are so similar to tensors, we can convert most tensors to numpy arrays (and back) but we don't need it too often.\n",
        "\n",
        "#### Initialization\n",
        "\n",
        "Let's first start by looking at different ways of creating a tensor. There are many possible options, the simplest one is to call `torch.Tensor` passing the desired shape as input argument:"
      ],
      "metadata": {
        "id": "ngFCfpwCgREI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.Tensor(2, 3, 4)\n",
        "print(x)"
      ],
      "metadata": {
        "id": "uDQiOHawgFPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function `torch.Tensor` allocates memory for the desired tensor, but reuses any values that have already been in the memory. To directly assign values to the tensor during initialization, there are many alternatives including:\n",
        "\n",
        "* `torch.zeros`: Creates a tensor filled with zeros\n",
        "* `torch.ones`: Creates a tensor filled with ones\n",
        "* `torch.rand`: Creates a tensor with random values uniformly sampled between 0 and 1\n",
        "* `torch.randn`: Creates a tensor with random values sampled from a normal distribution with mean 0 and variance 1\n",
        "* `torch.arange`: Creates a tensor containing the values $N,N+1,N+2,...,M$\n",
        "* `torch.Tensor` (input list): Creates a tensor from the list elements you provide"
      ],
      "metadata": {
        "id": "hLIXyENcgWh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor from a (nested) list\n",
        "x = torch.Tensor([[1, 2], [3, 4]])\n",
        "print(x)"
      ],
      "metadata": {
        "id": "UyBYyCOegTDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor with random values between 0 and 1 with the shape [2, 3, 4]\n",
        "x = torch.rand(2, 3, 4)\n",
        "print(x)\n",
        "print(x.shape)"
      ],
      "metadata": {
        "id": "37LE_1X0gZB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tensor to Numpy, and Numpy to Tensor\n",
        "\n",
        "Tensors can be converted to numpy arrays, and numpy arrays back to tensors. To transform a numpy array into a tensor, we can use the function `torch.from_numpy`:"
      ],
      "metadata": {
        "id": "Ew-ZZuvigdsw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np_arr = np.array([[1, 2], [3, 4]])\n",
        "tensor = torch.from_numpy(np_arr)\n",
        "\n",
        "print(\"Numpy array:\", np_arr)\n",
        "print(\"PyTorch tensor:\", tensor)"
      ],
      "metadata": {
        "id": "xVwTEf8DgeDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To transform a PyTorch tensor back to a numpy array, we can use the function `.numpy()` on tensors:"
      ],
      "metadata": {
        "id": "mWn5KkHXghtv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.arange(4)\n",
        "np_arr = tensor.numpy()\n",
        "\n",
        "print(\"PyTorch tensor:\", tensor)\n",
        "print(\"Numpy array:\", np_arr)"
      ],
      "metadata": {
        "id": "zDu5t-bUgh79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The conversion of tensors to numpy require the tensor to be on the CPU, and not the GPU (more on GPU support in a later section). In case you have a tensor on GPU, you need to call `.cpu()` on the tensor beforehand. Hence, you get a line like `np_arr = tensor.cpu().numpy()`."
      ],
      "metadata": {
        "id": "SRgeGtXmglxN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Basic Operations\n"
      ],
      "metadata": {
        "id": "If8Fn80mguoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = torch.rand(2, 3)\n",
        "x2 = torch.rand(2, 3)\n",
        "y = x1 + x2\n",
        "\n",
        "print(\"X1\", x1)\n",
        "print(\"X2\", x2)\n",
        "print(\"Y\", y)"
      ],
      "metadata": {
        "id": "FTS9VAVWgmHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = torch.rand(2, 3)\n",
        "x2 = torch.rand(2, 3)\n",
        "print(\"X1 (before)\", x1)\n",
        "print(\"X2 (before)\", x2)\n",
        "\n",
        "x2.add_(x1)\n",
        "print(\"X1 (after)\", x1)\n",
        "print(\"X2 (after)\", x2)"
      ],
      "metadata": {
        "id": "TBHw7x7jgxpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In-place operations are usually marked with a underscore postfix (e.g. \"add_\" instead of \"add\").\n",
        "\n",
        "Another common operation aims at changing the shape of a tensor. A tensor of size (2,3) can be re-organized to any other shape with the same number of elements (e.g. a tensor of size (6), or (3,2), ...). In PyTorch, this operation is called `view`:"
      ],
      "metadata": {
        "id": "Tsvfxz_7g0jZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(6)\n",
        "print(\"X\", x)"
      ],
      "metadata": {
        "id": "FJ3akcLwg5QO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = x.view(2, 3)\n",
        "print(\"X\", x)"
      ],
      "metadata": {
        "id": "mgPBjXQbg5Sn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = x.permute(1, 0) # Swapping dimension 0 and 1\n",
        "print(\"X\", x)"
      ],
      "metadata": {
        "id": "EmgJr1nAg-dn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GPU support"
      ],
      "metadata": {
        "id": "6EURHdNfiRQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_avail = torch.cuda.is_available()\n",
        "print(f\"Is the GPU available? {gpu_avail}\")"
      ],
      "metadata": {
        "id": "WOAcsnKoiTub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"Device\", device)"
      ],
      "metadata": {
        "id": "gO-TPsWwjN5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.zeros(2, 3)\n",
        "x = x.to(device)\n",
        "print(\"X\", x)"
      ],
      "metadata": {
        "id": "WIxwjjGGit23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In case you have a GPU, you should now see the attribute `device='cuda:0'` being printed next to your tensor. The zero next to cuda indicates that this is the zero-th GPU device on your computer. PyTorch also supports multi-GPU systems, but this you will only need once you have very big networks to train (if interested, see the [PyTorch documentation](https://pytorch.org/docs/stable/distributed.html#distributed-basics)). We can also compare the runtime of a large matrix multiplication on the CPU with a operation on the GPU:"
      ],
      "metadata": {
        "id": "yfnrkVv1jQRM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(5000, 5000)\n",
        "\n",
        "## CPU version\n",
        "start_time = time.time()\n",
        "_ = torch.matmul(x, x)\n",
        "end_time = time.time()\n",
        "print(f\"CPU time: {(end_time - start_time):6.5f}s\")\n",
        "\n",
        "## GPU version\n",
        "x = x.to(device)\n",
        "_ = torch.matmul(x, x)  # First operation to 'burn in' GPU\n",
        "# CUDA is asynchronous, so we need to use different timing functions\n",
        "start = torch.cuda.Event(enable_timing=True)\n",
        "end = torch.cuda.Event(enable_timing=True)\n",
        "start.record()\n",
        "_ = torch.matmul(x, x)\n",
        "end.record()\n",
        "torch.cuda.synchronize()  # Waits for everything to finish running on the GPU\n",
        "print(f\"GPU time: {0.001 * start.elapsed_time(end):6.5f}s\")  # Milliseconds to seconds"
      ],
      "metadata": {
        "id": "CT8SX9k2jV-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dynamic Computation Graph and Backpropagation\n",
        "\n",
        "One of the main reasons for using PyTorch in Deep Learning projects is that we can automatically get **gradients/derivatives** of functions that we define. We will mainly use PyTorch for implementing neural networks, and they are just fancy functions. If we use weight matrices in our function that we want to learn, then those are called the **parameters** or simply the **weights**.\n",
        "\n",
        "If our neural network would output a single scalar value, we would talk about taking the **derivative**, but you will see that quite often we will have **multiple** output variables (\"values\"); in that case we talk about **gradients**. It's a more general term.\n",
        "\n",
        "Given an input $\\mathbf{x}$, we define our function by **manipulating** that input, usually by matrix-multiplications with weight matrices and additions with so-called bias vectors. As we manipulate our input, we are automatically creating a **computational graph**. This graph shows how to arrive at our output from our input. \n",
        "PyTorch is a **define-by-run** framework; this means that we can just do our manipulations, and PyTorch will keep track of that graph for us. Thus, we create a dynamic computation graph along the way.\n",
        "\n",
        "So, to recap: the only thing we have to do is to compute the **output**, and then we can ask PyTorch to automatically get the **gradients**. \n",
        "\n",
        "> **Note:  Why do we want gradients?** Consider that we have defined a function, a neural net, that is supposed to compute a certain output $y$ for an input vector $\\mathbf{x}$. We then define an **error measure** that tells us how wrong our network is; how bad it is in predicting output $y$ from input $\\mathbf{x}$. Based on this error measure, we can use the gradients to **update** the weights $\\mathbf{W}$ that were responsible for the output, so that the next time we present input $\\mathbf{x}$ to our network, the output will be closer to what we want.\n",
        "\n",
        "The first thing we have to do is to specify which tensors require gradients. By default, when we create a tensor, it does not require gradients."
      ],
      "metadata": {
        "id": "tXFGealwhUTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones((3,))\n",
        "print(x.requires_grad)"
      ],
      "metadata": {
        "id": "uxAXf-n4hUzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can change this for an existing tensor using the function `requires_grad_()` (underscore indicating that this is a in-place operation). Alternatively, when creating a tensor, you can pass the argument `requires_grad=True` to most initializers we have seen above."
      ],
      "metadata": {
        "id": "sX5lX1p-hYar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.requires_grad_(True)\n",
        "print(x.requires_grad)"
      ],
      "metadata": {
        "id": "f5-C-iAZhYyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to get familiar with the concept of a computation graph, we will create one for the following function:\n",
        "\n",
        "$$y = \\frac{1}{|x|}\\sum_i \\left[(x_i + 2)^2 + 3\\right]$$\n",
        "\n",
        "You could imagine that $x$ are our parameters, and we want to optimize (either maximize or minimize) the output $y$. For this, we want to obtain the gradients $\\partial y / \\partial \\mathbf{x}$. For our example, we'll use $\\mathbf{x}=[0,1,2]$ as our input."
      ],
      "metadata": {
        "id": "DRFyBLqxhaYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(3, dtype=torch.float32, requires_grad=True) # Only float tensors can have gradients\n",
        "print(\"X\", x)"
      ],
      "metadata": {
        "id": "1yWKQVIBhcwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's build the computation graph step by step. You can combine multiple operations in a single line, but we will separate them here to get a better understanding of how each operation is added to the computation graph."
      ],
      "metadata": {
        "id": "mLQ-m-C4hhSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = x + 2\n",
        "b = a ** 2\n",
        "c = b + 3\n",
        "y = c.mean()\n",
        "print(\"Y\", y)"
      ],
      "metadata": {
        "id": "49u8xvJ_hjqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the statements above, we have created a computation graph that looks similar to the figure below:\n",
        "\n",
        "![pytorch_computation_graph.svg](data:image/svg+xml;base64,<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" width="171px" height="301px" viewBox="-0.5 -0.5 171 301"><defs/><g><ellipse cx="145" cy="15" rx="25" ry="15" fill="#cdeb8b" stroke="#36393d" pointer-events="all"/><g transform="translate(-0.5 -0.5)"><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 48px; height: 1px; padding-top: 15px; margin-left: 121px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; "><div style="display: inline-block; font-size: 15px; font-family: Helvetica; color: #000000; line-height: 1.2; pointer-events: all; font-weight: bold; white-space: normal; word-wrap: normal; ">x</div></div></div></foreignObject><text x="145" y="20" fill="#000000" font-family="Helvetica" font-size="15px" text-anchor="middle" font-weight="bold">x</text></switch></g><ellipse cx="65" cy="15" rx="25" ry="15" fill="#eeeeee" stroke="#36393d" pointer-events="all"/><g transform="translate(-0.5 -0.5)"><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 48px; height: 1px; padding-top: 15px; margin-left: 41px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; "><div style="display: inline-block; font-size: 15px; font-family: Helvetica; color: #000000; line-height: 1.2; pointer-events: all; font-weight: bold; white-space: normal; word-wrap: normal; "><span style="font-weight: normal">2</span></div></div></div></foreignObject><text x="65" y="20" fill="#000000" font-family="Helvetica" font-size="15px" text-anchor="middle" font-weight="bold">2</text></switch></g><ellipse cx="105" cy="85" rx="25" ry="15" fill="#ffcc99" stroke="#36393d" pointer-events="all"/><g transform="translate(-0.5 -0.5)"><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 48px; height: 1px; padding-top: 85px; margin-left: 81px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; "><div style="display: inline-block; font-size: 15px; font-family: Helvetica; color: #000000; line-height: 1.2; pointer-events: all; font-weight: bold; white-space: normal; word-wrap: normal; "><span>a</span></div></div></div></foreignObject><text x="105" y="90" fill="#000000" font-family="Helvetica" font-size="15px" text-anchor="middle" font-weight="bold">a</text></switch></g><path d="M 112.58 70.71 L 132.15 34.12" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="stroke"/><path d="M 134.62 29.49 L 134.41 37.31 L 132.15 34.12 L 128.24 34.01 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="all"/><path d="M 98.45 69.49 L 77.06 33.52" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="stroke"/><path d="M 74.37 29.01 L 80.96 33.24 L 77.06 33.52 L 74.94 36.82 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="all"/><ellipse cx="105" cy="155" rx="25" ry="15" fill="#ffcc99" stroke="#36393d" pointer-events="all"/><g transform="translate(-0.5 -0.5)"><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 48px; height: 1px; padding-top: 155px; margin-left: 81px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; "><div style="display: inline-block; font-size: 15px; font-family: Helvetica; color: #000000; line-height: 1.2; pointer-events: all; font-weight: bold; white-space: normal; word-wrap: normal; "><span>b</span></div></div></div></foreignObject><text x="105" y="160" fill="#000000" font-family="Helvetica" font-size="15px" text-anchor="middle" font-weight="bold">b</text></switch></g><path d="M 105 140 L 105 106.37" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="stroke"/><path d="M 105 101.12 L 108.5 108.12 L 105 106.37 L 101.5 108.12 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="all"/><ellipse cx="65" cy="225" rx="25" ry="15" fill="#ffcc99" stroke="#36393d" pointer-events="all"/><g transform="translate(-0.5 -0.5)"><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 48px; height: 1px; padding-top: 225px; margin-left: 41px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; "><div style="display: inline-block; font-size: 15px; font-family: Helvetica; color: #000000; line-height: 1.2; pointer-events: all; font-weight: bold; white-space: normal; word-wrap: normal; "><span>c</span></div></div></div></foreignObject><text x="65" y="230" fill="#000000" font-family="Helvetica" font-size="15px" text-anchor="middle" font-weight="bold">c</text></switch></g><ellipse cx="25" cy="155" rx="25" ry="15" fill="#eeeeee" stroke="#36393d" pointer-events="all"/><g transform="translate(-0.5 -0.5)"><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 48px; height: 1px; padding-top: 155px; margin-left: 1px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; "><div style="display: inline-block; font-size: 15px; font-family: Helvetica; color: #000000; line-height: 1.2; pointer-events: all; font-weight: bold; white-space: normal; word-wrap: normal; "><span style="font-weight: normal">3</span></div></div></div></foreignObject><text x="25" y="160" fill="#000000" font-family="Helvetica" font-size="15px" text-anchor="middle" font-weight="bold">3</text></switch></g><path d="M 71.78 210.56 L 88.84 174.35" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="stroke"/><path d="M 91.07 169.6 L 91.26 177.43 L 88.84 174.35 L 84.92 174.44 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="all"/><path d="M 57 211.71 L 36.16 174.75" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="stroke"/><path d="M 33.58 170.18 L 40.07 174.56 L 36.16 174.75 L 33.97 177.99 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="all"/><ellipse cx="65" cy="285" rx="25" ry="15" fill="#ffcc99" stroke="#36393d" pointer-events="all"/><g transform="translate(-0.5 -0.5)"><switch><foreignObject style="overflow: visible; text-align: left;" pointer-events="none" width="100%" height="100%" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: flex; align-items: unsafe center; justify-content: unsafe center; width: 48px; height: 1px; padding-top: 285px; margin-left: 41px;"><div style="box-sizing: border-box; font-size: 0; text-align: center; "><div style="display: inline-block; font-size: 15px; font-family: Helvetica; color: #000000; line-height: 1.2; pointer-events: all; font-weight: bold; white-space: normal; word-wrap: normal; "><span style="font-weight: normal">y</span></div></div></div></foreignObject><text x="65" y="290" fill="#000000" font-family="Helvetica" font-size="15px" text-anchor="middle" font-weight="bold">y</text></switch></g><path d="M 65 270 L 65 246.37" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="stroke"/><path d="M 65 241.12 L 68.5 248.12 L 65 246.37 L 61.5 248.12 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="all"/></g><switch><g requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"/><a transform="translate(0,-5)" xlink:href="https://desk.draw.io/support/solutions/articles/16000042487" target="_blank"><text text-anchor="middle" font-size="10px" x="50%" y="100%">Viewer does not support full SVG 1.1</text></a></switch></svg>)\n",
        "\n",
        "We calculate $a$ based on the inputs $x$ and the constant $2$, $b$ is $a$ squared, and so on. The visualization is an abstraction of the dependencies between inputs and outputs of the operations we have applied.\n",
        "Each node of the computation graph has automatically defined a function for calculating the gradients with respect to its inputs, `grad_fn`. You can see this when we printed the output tensor $y$. This is why the computation graph is usually visualized in the reverse direction (arrows point from the result to the inputs). We can perform backpropagation on the computation graph by calling the function `backward()` on the last output, which effectively calculates the gradients for each tensor that has the property `requires_grad=True`:"
      ],
      "metadata": {
        "id": "IuPSEbQmhnUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y.backward()"
      ],
      "metadata": {
        "id": "34H59ODhhnod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`x.grad` will now contain the gradient $\\partial y/ \\partial \\mathcal{x}$, and this gradient indicates how a change in $\\mathbf{x}$ will affect output $y$ given the current input $\\mathbf{x}=[0,1,2]$:"
      ],
      "metadata": {
        "id": "yj9ls_fSiFzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.grad)"
      ],
      "metadata": {
        "id": "pUzoypZKiGNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also verify these gradients by hand. We will calculate the gradients using the chain rule, in the same way as PyTorch did it:\n",
        "\n",
        "$$\\frac{\\partial y}{\\partial x_i} = \\frac{\\partial y}{\\partial c_i}\\frac{\\partial c_i}{\\partial b_i}\\frac{\\partial b_i}{\\partial a_i}\\frac{\\partial a_i}{\\partial x_i}$$\n",
        "\n",
        "Note that we have simplified this equation to index notation, and by using the fact that all operation besides the mean do not combine the elements in the tensor. The partial derivatives are:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial a_i}{\\partial x_i} = 1,\\hspace{1cm}\n",
        "\\frac{\\partial b_i}{\\partial a_i} = 2\\cdot a_i\\hspace{1cm}\n",
        "\\frac{\\partial c_i}{\\partial b_i} = 1\\hspace{1cm}\n",
        "\\frac{\\partial y}{\\partial c_i} = \\frac{1}{3}\n",
        "$$\n",
        "\n",
        "Hence, with the input being $\\mathbf{x}=[0,1,2]$, our gradients are $\\partial y/\\partial \\mathbf{x}=[4/3,2,8/3]$. The previous code cell should have printed the same result."
      ],
      "metadata": {
        "id": "SAjQg5reiHwa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's build our first Neural Network!"
      ],
      "metadata": {
        "id": "rMpYB7E3jl65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import random_split, DataLoader, TensorDataset\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "from timeit import default_timer as timer\n",
        "from functools import partial\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (12.0, 8.0)\n",
        "plt.rcParams['font.size'] = 16"
      ],
      "metadata": {
        "id": "CMHWUb7Jj-Mz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### prepapre the Train/Val/Test split \n",
        "We are going to classify images from CIFAR10, let's first download the dataset"
      ],
      "metadata": {
        "id": "tl6T_miQjtDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tsfms = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda z: z.flatten())]) \n",
        "train_ds = torchvision.datasets.SVHN(root=\"/data/\", split='train', transform=tsfms, download=True)\n",
        "test_ds = torchvision.datasets.SVHN(root=\"/data/\", split='test', transform=tsfms, download=True)\n",
        "\n",
        "n_classes = 10\n",
        "n_features = len(train_ds[0][0])"
      ],
      "metadata": {
        "id": "mheve-u1jpx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f, axarr = plt.subplots(1,2, squeeze=False)\n",
        "axarr[0,0].imshow(test_ds[0][0].reshape(3,32,32).permute(1,2,0))\n",
        "axarr[0,1].imshow(train_ds[0][0].reshape(3,32,32).permute(1,2,0))"
      ],
      "metadata": {
        "id": "PUlnsRp7MWuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### We create a small validation set from the training set"
      ],
      "metadata": {
        "id": "VmPTtqPhkYBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "splitted_datasets = torch.utils.data.random_split(train_ds, [len(train_ds)-5000, 5000])\n",
        "actual_train_subds = splitted_datasets[0]\n",
        "valid_subds = splitted_datasets[1]"
      ],
      "metadata": {
        "id": "MfooUAojkBIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The data loader class\n",
        "\n",
        "The class `torch.utils.data.DataLoader` represents a Python iterable over a dataset with support for automatic batching, multi-process data loading and many more features. The data loader communicates with the dataset using the function `__getitem__`, and stacks its outputs as tensors over the first dimension to form a batch.\n",
        "In contrast to the dataset class, we usually don't have to define our own data loader class, but can just create an object of it with the dataset as input. Additionally, we can configure our data loader with the following input arguments (only a selection, see full list [here](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)):\n",
        "\n",
        "* `batch_size`: Number of samples to stack per batch\n",
        "* `shuffle`: If True, the data is returned in a random order. This is important during training for introducing stochasticity. \n",
        "* `num_workers`: Number of subprocesses to use for data loading. The default, 0, means that the data will be loaded in the main process which can slow down training for datasets where loading a data point takes a considerable amount of time (e.g. large images). More workers are recommended for those, but can cause issues on Windows computers. For tiny datasets as ours, 0 workers are usually faster.\n",
        "* `pin_memory`: If True, the data loader will copy Tensors into CUDA pinned memory before returning them. This can save some time for large data points on GPUs. Usually a good practice to use for a training set, but not necessarily for validation and test to save memory on the GPU.\n",
        "* `drop_last`: If True, the last batch is dropped in case it is smaller than the specified batch size. This occurs when the dataset size is not a multiple of the batch size. Only potentially helpful during training to keep a consistent batch size.\n",
        "\n",
        "Let's create a simple data loader below:"
      ],
      "metadata": {
        "id": "ZR8Cj93vnSLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 256\n",
        "\n",
        "train_dl = torch.utils.data.DataLoader(actual_train_subds, batch_size=batch_size, shuffle=True)\n",
        "valid_dl = torch.utils.data.DataLoader(valid_subds, batch_size=batch_size)\n",
        "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "J_7Pg2jAkH3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# next(iter(...)) catches the first batch of the data loader\n",
        "# If shuffle is True, this will return a different batch every time we run this cell\n",
        "# For iterating over the whole dataset, we can simple use \"for batch in data_loader: ...\"\n",
        "data_inputs, data_labels = next(iter(train_dl))\n",
        "\n",
        "# The shape of the outputs are [batch_size, d_1,...,d_N] where d_1,...,d_N are the \n",
        "# dimensions of the data point returned from the dataset class\n",
        "print(\"Data inputs\", data_inputs.shape, \"\\n\", data_inputs)\n",
        "print(\"Data labels\", data_labels.shape, \"\\n\", data_labels)"
      ],
      "metadata": {
        "id": "1rR2Vw5mnZjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create the network"
      ],
      "metadata": {
        "id": "OwUJEONtkngC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will then create our first Neural Network. One way to create Neural Networks in PyTorch is by subclassing `torch.nn.Module`. In this way, our model will inherit a lot of ready-to-use convinience functions (access to parameters for optimization, get/set parameters, ...). \n",
        "\n",
        "We only need to create the layers we will use in the `__init__` function and define the `forward` function that specifies how to apply them. \n",
        "\n",
        "Layers are in turn subclasses of `torch.nn.Module`. In our example, we will use only linear layers, i.e. Fully Connected (FC) layers. Our network will have at least two FC layers: `self.first`, mapping the flattened input image into the (first) hidden representation, and `self.last`, mapping the (last) hidden representation into the scores for the classes.\n",
        "\n",
        "To play with varying depths and activation functions, we will have two additional parameters:\n",
        "\n",
        "\n",
        "*   `n_additional_hidden_layers`, specifies how many hidden layers our network has, beside `self.first`\n",
        "*   `use_relu`, if `False`, activations will be sigmoid functions, ReLUs otherwise\n",
        "\n",
        "Note that to store a variable number of layers in our network, we do not use plain PyTorch lists, but `torch.nn.ModuleList`. This is important to make PyTorch aware of the layers in the list, e.g. to set/get their parameters when calling the methods of the base `Module` class."
      ],
      "metadata": {
        "id": "M7bO5sVVkLaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Common template\n",
        "class SimpleClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, num_inputs, num_hidden, num_outputs):\n",
        "        super().__init__()\n",
        "        # Initialize the modules we need to build the network\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Perform the calculation of the model to determine the prediction\n",
        "        return x"
      ],
      "metadata": {
        "id": "TzdJdK_Mmhay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleClassifier(torch.nn.Module):\n",
        "  def __init__(self, n_features, hidden_width, n_classes, n_additional_hidden_layers=0):\n",
        "    super(SimpleClassifier, self).__init__()\n",
        "    self.first = torch.nn.Linear(n_features, hidden_width) \n",
        "    self.activation = torch.relu\n",
        "    self.last = torch.nn.Linear(hidden_width, n_classes)\n",
        "\n",
        "    self.additional_hidden_layers = torch.nn.ModuleList(\n",
        "        [torch.nn.Linear(hidden_width, hidden_width) for i in range(n_additional_hidden_layers)])\n",
        "  \n",
        "      \n",
        "  def forward(self, x):\n",
        "    x = self.first(x)\n",
        "    x = self.activation(x)\n",
        "    for layer in self.additional_hidden_layers:\n",
        "      x = layer(x)\n",
        "      x = self.activation(x)\n",
        "    x = self.last(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "ahhsPujbkL7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_width = 128\n",
        "\n",
        "model = SimpleClassifier(n_features, hidden_width, n_classes, n_additional_hidden_layers=1)\n",
        "for p in model.parameters():\n",
        "  print(type(p), p.shape)"
      ],
      "metadata": {
        "id": "2Z-UyxAAn_fX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each linear layer has a weight matrix of the shape `[output, input]`, and a bias of the shape `[output]`. The activation function does not have any parameters. Note that parameters are only registered for `nn.Module` objects that are direct object attributes, i.e. `self.a = ...`. "
      ],
      "metadata": {
        "id": "MqCpCn4vmt1i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`state_dict()` instead is an (Ordered) Dictionary, which associates each variable storing a layer in our classes with its parameters. It is therefore useful to obtain a snapshot of the parameters of our model that can later be restored by calling `load_state_dict()`."
      ],
      "metadata": {
        "id": "OeyYTq2hqYDy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(model.state_dict())"
      ],
      "metadata": {
        "id": "Viqn0fgyqn0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.state_dict().keys()"
      ],
      "metadata": {
        "id": "TwTXNE8DqpLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.state_dict()[\"first.bias\"]"
      ],
      "metadata": {
        "id": "dBoWl-lpqqZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Push model to device. Has to be only done once\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "hHdm_zLjpwCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimization\n",
        "\n",
        "After defining the model and the dataset, it is time to prepare the optimization of the model. During training, we will perform the following steps:\n",
        "\n",
        "1. Get a batch from the data loader\n",
        "2. Obtain the predictions from the model for the batch\n",
        "3. Calculate the loss based on the difference between predictions and labels\n",
        "4. Backpropagation: calculate the gradients for every parameter with respect to the loss\n",
        "5. Update the parameters of the model in the direction of the gradients\n"
      ],
      "metadata": {
        "id": "pMJ3jFu-nujg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Stochastic Gradient Descent\n",
        "\n",
        "For updating the parameters, PyTorch provides the package `torch.optim` that has most popular optimizers implemented. Will for now use `torch.optim.Adam`."
      ],
      "metadata": {
        "id": "qehLOzi1n9v4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "JAK9JOl3o-mE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The optimizer provides two useful functions: `optimizer.step()`, and `optimizer.zero_grad()`. The step function updates the parameters based on the gradients as explained above. The function `optimizer.zero_grad()` sets the gradients of all parameters to zero. While this function seems less relevant at first, it is a crucial pre-step before performing backpropagation. If we call the `backward` function on the loss while the parameter gradients are non-zero from the previous batch, the new gradients would actually be added to the previous ones instead of overwriting them. This is done because a parameter might occur multiple times in a computation graph, and we need to sum the gradients in this case instead of replacing them. Hence, remember to call `optimizer.zero_grad()` before calculating the gradients of a batch."
      ],
      "metadata": {
        "id": "RrM17i7spNNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ncorrect(scores, y):\n",
        "  y_hat = torch.argmax(scores, 1)\n",
        "  return (y_hat==y).sum()\n",
        "\n",
        "def accuracy(scores, y):\n",
        "  correct = ncorrect(scores, y)\n",
        "  return correct.true_divide(y.shape[0])\n",
        "  \n",
        "def train_loop(model, train_dl, epochs, opt, valid_dl=None, verbose=False):\n",
        "  best_valid_acc = 0\n",
        "  best_params = []\n",
        "  best_epoch = -1\n",
        "\n",
        "  for e in tqdm(range(epochs)):\n",
        "    model.train()\n",
        "    #train\n",
        "    train_loss = 0\n",
        "    train_samples = 0\n",
        "    train_acc = 0\n",
        "    for train_data in train_dl:\n",
        "      input = train_data[0].to(device)\n",
        "      labels = train_data[1].to(device)\n",
        "      scores = model(input)\n",
        "      loss = F.cross_entropy(scores, labels)\n",
        "      train_loss += loss.item() * input.shape[0]\n",
        "      train_samples += input.shape[0]\n",
        "      train_acc += ncorrect(scores, labels).item()\n",
        "      loss.backward()\n",
        "\n",
        "      opt.step()\n",
        "      opt.zero_grad()\n",
        "\n",
        "    train_acc /= train_samples\n",
        "    train_loss /= train_samples\n",
        "    \n",
        "    # validation\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      valid_loss = 0\n",
        "      valid_samples = 0\n",
        "      valid_acc = 0\n",
        "      if valid_dl is not None:\n",
        "        for valid_data in valid_dl:\n",
        "          input = valid_data[0].to(device)\n",
        "          labels = valid_data[1].to(device)\n",
        "          valid_scores = model(input)\n",
        "          valid_loss += F.cross_entropy(valid_scores, labels).item() * input.shape[0]\n",
        "          valid_samples += input.shape[0]\n",
        "          valid_acc += ncorrect(valid_scores, labels).item()\n",
        "        valid_acc /= valid_samples\n",
        "        valid_loss /= valid_samples\n",
        "      \n",
        "      if valid_dl is None or valid_acc > best_valid_acc:\n",
        "        best_valid_acc = valid_acc if valid_dl is not None else 0\n",
        "        best_params = model.state_dict()\n",
        "        torch.save(best_params, \"best_model.pth\")\n",
        "        best_epoch = e\n",
        "\n",
        "    if verbose and e % 5 == 0:\n",
        "      print(f\"Epoch {e}: train loss {train_loss:.3f} - train acc {train_acc:.3f}\" + (\"\" if valid_dl is None else f\" - valid loss {valid_loss:.3f} - valid acc {valid_acc:.3f}\"))\n",
        "  \n",
        "  if verbose and valid_dl is not None:\n",
        "    print(f\"Best epoch {best_epoch}, best acc {best_valid_acc}\")\n",
        "\n",
        "  return best_valid_acc, best_params, best_epoch"
      ],
      "metadata": {
        "id": "RMHsGa-kktk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the network"
      ],
      "metadata": {
        "id": "5C_cx4r3l3X3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "\n",
        "start = timer()\n",
        "best_valid_acc, best_params, best_epoch = train_loop(model, train_dl, epochs, optimizer, valid_dl=valid_dl, verbose=True)\n",
        "end = timer()\n",
        "print(f\"Elapsed time (s): {end-start}\")"
      ],
      "metadata": {
        "id": "xR8VRn7Vl4HT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the model "
      ],
      "metadata": {
        "id": "3DnMx-N8q6Vo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load state dict from the disk (make sure it is the same name as above)\n",
        "state_dict = torch.load(\"best_model.pth\")\n",
        "\n",
        "# Create a new model and load the state\n",
        "new_model = SimpleClassifier(n_features, hidden_width, n_classes, n_additional_hidden_layers=1)\n",
        "new_model.load_state_dict(state_dict)"
      ],
      "metadata": {
        "id": "pfWY1VuWq7Z4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now it's your turn!"
      ],
      "metadata": {
        "id": "YX5S0oEt1pJF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 1: Improve the Accuracy score\n",
        "\n",
        "Try to achieve a better accuracy on the validation set by modifying the previus model and manually tuning the hyper parameters such as the number of epochs, the learning rate, and the number of hidden layers. \n",
        "\n",
        "\n",
        "Suggestion: you can add [Batch Normalization](https://arxiv.org/abs/1502.03167). You can find the Normalization layers already implemented in [PyTorch](https://pytorch.org/docs/stable/nn.html#id1).\n",
        "\n",
        "use '''nn.Sequential()''' to stack togheter a block with the following \n",
        "structure:\n",
        "\n",
        "nn.Linear -> BatchNorm -> Activation\n",
        "\n",
        "Use the nn.Sequential() pytorch package to stack the previus three components into a single layer.\n",
        "\n",
        "**You should easily get 80% on the validation set**\n"
      ],
      "metadata": {
        "id": "FXoBf9ZF4o4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_linear_bn_relu(\n",
        "    name: str,\n",
        "    features_in: int,\n",
        "    features_out: int,\n",
        "    add_batch_norm: bool,\n",
        ") -> nn.Sequential:\n",
        "    \"\"\"Gets a sequential container with a sandwich of Linear, Relu and batch norm.\n",
        "\n",
        "    Args:\n",
        "        name: the name prefix to append to each layer in the container.\n",
        "        features_in: the number of the input channels.\n",
        "        features_out: the number of the output channels.\n",
        "        add_batch_norm: if True, add a batch normalization layer after the Linear layer.\n",
        "\n",
        "    Returns: the created sequential.\n",
        "    \"\"\"\n",
        "    container = nn.Sequential()\n",
        "    ############ Write your code here ############\n",
        "\n",
        "    #############################################\n",
        "\n",
        "\n",
        "    return container"
      ],
      "metadata": {
        "id": "J5wwRfF41r6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleClassifierBN(nn.Module):\n",
        "  def __init__(self, n_features, hidden_width, n_classes, n_additional_hidden_layers=0):\n",
        "    super(SimpleClassifierBN, self).__init__()\n",
        "    self.first = torch.nn.Linear(n_features, hidden_width)\n",
        "    self.bn = nn.BatchNorm1d(hidden_width)\n",
        "    self.activation = torch.relu\n",
        "    self.last = torch.nn.Linear(hidden_width, n_classes)\n",
        "\n",
        "    self.additional_hidden_layers = torch.nn.ModuleList(\n",
        "        [get_linear_bn_relu(name=f\"h_layer_{i}\", features_in=hidden_width, features_out=hidden_width, add_batch_norm=True)\n",
        "          for i in range(n_additional_hidden_layers)])\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.first(x)\n",
        "    x = self.bn(x)\n",
        "    x = self.activation(x)\n",
        "    for layer in self.additional_hidden_layers:\n",
        "      x = layer(x)\n",
        "      x = self.activation(x)\n",
        "    x = self.last(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "tH_HHQX041fR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model = SimpleClassifierBN(n_features, hidden_width, n_classes, n_additional_hidden_layers=3)\n",
        "new_model.to(device)\n",
        "optimizer = torch.optim.Adam(new_model.parameters(), lr=0.01)\n",
        "epochs = 25\n",
        "\n",
        "start = timer()\n",
        "best_valid_acc, best_params, best_epoch = train_loop(new_model, train_dl, epochs, optimizer, valid_dl=valid_dl, verbose=True)\n",
        "end = timer()\n",
        "print(f\"Elapsed time (s): {end-start}\")"
      ],
      "metadata": {
        "id": "s03EO1ev5JjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model.load_state_dict(torch.load('best_model.pth'))"
      ],
      "metadata": {
        "id": "IqtXRfKEg74z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 2: \n",
        "Compute the confusion matrix for the test set. Then, given the confusion matrix, compute the accuracy score."
      ],
      "metadata": {
        "id": "LAwjHfGV5Zyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10\n",
        "new_model.eval()\n",
        "confusion_matrix = torch.zeros(num_classes, num_classes)\n",
        "############ Write your code here ############\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(test_dl):\n",
        "        input, gt = data\n",
        "        input = input.to(device)\n",
        "        gt = gt.to(device)\n",
        "\n",
        "test_accuracy = torch.diagonal(confusion_matrix).sum()/confusion_matrix.sum()\n",
        "#############################################\n",
        "print(test_accuracy)\n"
      ],
      "metadata": {
        "id": "vuGfiC3vZMzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "confusion_matrix /= confusion_matrix.sum(1)\n",
        "confusion_matrix *= 100\n",
        "df_cm = pd.DataFrame(confusion_matrix)\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.heatmap(df_cm, annot=True)"
      ],
      "metadata": {
        "id": "TtbAcZVkbhZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 3:\n",
        "Rewrite the forward model to return the embedding rather than the classification scores.\n",
        "**Note that you don't have to retrain the model again!**\n",
        "\n",
        "Then, show the three nearest neighbors in the train set for element with index 0 in the test set."
      ],
      "metadata": {
        "id": "xjVl1dHK5Z3w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleClassifierBN_2(nn.Module):\n",
        "  def __init__(self, n_features, hidden_width, n_classes, n_additional_hidden_layers=0):\n",
        "    super(SimpleClassifierBN_2, self).__init__()\n",
        "    ############ Write your code here ############\n",
        "\n",
        "  #############################################\n",
        "\n",
        "  def forward(self, x):\n",
        "    ############ Write your code here ############\n",
        "\n",
        "    #############################################"
      ],
      "metadata": {
        "id": "akoEz0AdveM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load state dict from the disk (make sure it is the same name as above)\n",
        "state_dict = torch.load(\"best_model.pth\")\n",
        "\n",
        "# Create a new model and load the state\n",
        "new_model = SimpleClassifierBN_2(n_features, hidden_width, n_classes, n_additional_hidden_layers=3)\n",
        "new_model.load_state_dict(state_dict)\n",
        "new_model.to(device)\n",
        "new_model.eval()"
      ],
      "metadata": {
        "id": "3teK1uxPvuoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embeddings(model, dl):\n",
        "  model.eval()\n",
        "  embeddings = []\n",
        "  labels = []\n",
        "  \n",
        "############ Write your code here ############\n",
        "  with torch.no_grad():\n",
        "      for data in dl:\n",
        "          input, gt = data\n",
        "          input = input.to(device)\n",
        "          gt = gt.to(device)\n",
        "\n",
        "          # calculate the embeddings by running images through the network and store them\n",
        "          \n",
        "#############################################\n",
        "  return embeddings, labels\n",
        "\n",
        "train_dl = torch.utils.data.DataLoader(actual_train_subds, batch_size=batch_size, shuffle=False)\n",
        "embeddings_train, labels_train = get_embeddings(new_model, train_dl)\n",
        "print(embeddings_train.shape, labels_train.shape)\n",
        "embeddings_test, labels_test = get_embeddings(new_model, test_dl)\n",
        "print(embeddings_test.shape, labels_test.shape)"
      ],
      "metadata": {
        "id": "cgknZDtH4rpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############ Write your code here ############\n",
        "\n",
        "elem_idx = 0\n",
        "\n",
        "#############################################\n"
      ],
      "metadata": {
        "id": "9oUEQ70OE5OT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LV6cSOHwr8ks"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}