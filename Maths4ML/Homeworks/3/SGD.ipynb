{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from math import exp\n","import sklearn.model_selection \n","import pandas as pd\n"]},{"cell_type":"markdown","metadata":{},"source":["# stochastic gradient descent (SGD)\n","using batches to fasten gradient computation (approximation)\n","\n","SGD has to be implemented with static stepsize"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["def sigmoid(x): #giusto perforza\n","    return 1/(1-np.exp(-x))\n","\n","def f(w, x): #giusto, ma bigÃ¬sogna capire chi fa xhat\n","    #xhat=np.concatenate((x, np.ones((1, x.shape[1]))), axis=0)\n","    return sigmoid(x.T@w)\n","\n","def MSE(y, y1): #giusto, bisogna passare f come y e label(Y) come y1\n","    return (np.linalg.norm(y-y1)**2)/y.size[0]\n","\n","def l(w,D): # giusto\n","    X,Y=D\n","    return (MSE(f(w,X), Y))\n","\n","#gradient of l function grad_l\n","def grad_l(w, D):\n","    #D is the current batch: a tuple (Mx, My)\n","    #Mx is d x M\n","    #My is M\n","    Mx, My=D\n","    d, N=Mx.shape\n","    return (sigmoid(Mx.T@w).T@(1-sigmoid(Mx.T@w))*Mx@(f(w,Mx)-My)).T\n","\n","#gradient of SGD \n","def grad(w, D):\n","    #D is the current batch: a tuple (Mx, My)\n","    #gradient of SGD (sommatoria dei gradienti degli indici del batch [subset M])\n","    #this is an approximation of the gradiant, it isn't for sure the direction of steepest descent\n","    Mx, My=D\n","    d, N=Mx.shape\n","    #sum of the gradients (grad_l) of the indexes of the batch\n","    return np.sum(grad_l(w, D), axis=1)\n","\n","    \n","\n","\n","def SGD(l, grad_l, w0, D, batch_size, n_epochs): #D is a tuple (x,y)\n","    #initialization\n","    a=1 #fixed\n","    # D =(X,Y) where X is d x N \n","    # Y is N\n","    X, Y= D\n","    d,N=X.shape\n","    n_batch_per_epoch=int(N/batch_size)\n","    \n","    #definitions\n","    f_val=np.zeros((n_epochs, N))\n","    x_val=np.zeros((n_epochs, N))\n","    grads=np.zeros((n_epochs, N))\n","    err=np.zeros((n_epochs, N))\n","    w=w0\n","    i=0\n","    batchInd=np.zeros(batch_size)\n","    \n","    #loop\n","    conditions=True\n","    X_backup=X\n","    Y_backup=Y\n","    shuffledInd=np.arange(N)\n","    print(shuffledInd.shape)\n","\n","    for epoch in range(n_epochs):\n","        #NOTA: YOU HAVE TO SHUFFLE AGAIN AFTER EACH EPOCH!!!!\n","        print(f\"epoch {epoch}/{n_epochs}\")\n","        for k in range (n_batch_per_epoch):\n","            print(f\"batch {k}/{n_batch_per_epoch}\")\n","            #sample M from D\n","            batchInd=shuffledInd[batch_size*k : batch_size*(k+1)]\n","            Mx=X[:,batchInd] #batch di X\n","            My=Y[batchInd]#batch di Y\n","            M=(Mx, My)\n","            #remove Mx and My from X and Y\n","            X=np.delete(X, batchInd, axis=1)\n","            Y=np.delete(Y, batchInd, axis=0)\n","            #update w\n","            w=w0-a*grad(w,M)\n","            #assignments\n","            f_val[epoch,i]=l(w, M)\n","            x_val[epoch, i]=w\n","            grads[epoch, i]=grad(w,M)\n","            err[epoch, i]=MSE(f(w, Mx), My)\n","            #restart \n","            w0=w\n","            i+=1\n","        #reload X and Y and restart\n","        X=X_backup\n","        Y=Y_backup\n","        i=0\n","        shuffledInd=np.random.shuffle(np.arange(N)) #shuffle indexes\n","\n","         \n","    return f_val, x_val, grads, err\n"," #REMEMBER: w0 in SGD should be chosen randomly (sample from Gaussian), and not fixed\n"," #(upgrade): modify the code above to return f_val (over M)\n"," #f_val[k]=l(w_k, M)\n","\n","\n"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["shape of X: (784, 9035)\n","(6053,)\n","epoch 0/10\n","batch 0/60\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\gnele\\AppData\\Local\\Temp\\ipykernel_10336\\2469562586.py:2: RuntimeWarning: overflow encountered in exp\n","  return 1/(1-np.exp(-x))\n"]},{"ename":"TypeError","evalue":"'int' object is not subscriptable","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn [29], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m w0\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mnormal(\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m,(d,\u001b[39m1\u001b[39m))\n\u001b[0;32m     22\u001b[0m D\u001b[39m=\u001b[39m(X_train, y_train)\n\u001b[1;32m---> 23\u001b[0m f_val, x_val, grads, err\u001b[39m=\u001b[39mSGD(l, grad_l, w0, D, batch_size\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, n_epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n","Cell \u001b[1;32mIn [28], line 78\u001b[0m, in \u001b[0;36mSGD\u001b[1;34m(l, grad_l, w0, D, batch_size, n_epochs)\u001b[0m\n\u001b[0;32m     76\u001b[0m w\u001b[39m=\u001b[39mw0\u001b[39m-\u001b[39ma\u001b[39m*\u001b[39mgrad(w,M)\n\u001b[0;32m     77\u001b[0m \u001b[39m#assignments\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m f_val[epoch,i]\u001b[39m=\u001b[39ml(w, M)\n\u001b[0;32m     79\u001b[0m x_val[epoch, i]\u001b[39m=\u001b[39mw\n\u001b[0;32m     80\u001b[0m grads[epoch, i]\u001b[39m=\u001b[39mgrad(w,M)\n","Cell \u001b[1;32mIn [28], line 13\u001b[0m, in \u001b[0;36ml\u001b[1;34m(w, D)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39ml\u001b[39m(w,D): \u001b[39m# giusto\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     X,Y\u001b[39m=\u001b[39mD\n\u001b[1;32m---> 13\u001b[0m     \u001b[39mreturn\u001b[39;00m (MSE(f(w,X), Y))\n","Cell \u001b[1;32mIn [28], line 9\u001b[0m, in \u001b[0;36mMSE\u001b[1;34m(y, y1)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mMSE\u001b[39m(y, y1): \u001b[39m#giusto, bisogna passare f come y e label(Y) come y1\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     \u001b[39mreturn\u001b[39;00m (np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mnorm(y\u001b[39m-\u001b[39my1)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)\u001b[39m/\u001b[39my\u001b[39m.\u001b[39;49msize[\u001b[39m0\u001b[39;49m]\n","\u001b[1;31mTypeError\u001b[0m: 'int' object is not subscriptable"]}],"source":["Data=pd.read_csv(\"../2/data.csv\")\n","#print(D.head())\n","Data=np.array(Data)\n","X=Data[:,1:]\n","Y=Data[:,0]\n","#isolate digits 3 and 1\n","i1= (Y==1)\n","i3= (Y==3)\n","X=X[i1+i3,:]\n","Y=Y[i1+i3]\n","N,d=X.shape\n","Y=Y.reshape((N, 1))\n","N,d=X.shape\n","X_train, X_test, y_train, y_test= sklearn.model_selection.train_test_split(X, Y, test_size=0.33, random_state=1)\n","X=X.T\n","X_train=X_train.T\n","X_test=X_test.T\n","print(f\"shape of X: {X.shape}\")\n","#call SGD\n","#initialize w0 with normal distribution\n","w0=np.random.normal(0,1,(d,1))\n","D=(X_train, y_train)\n","f_val, x_val, grads, err=SGD(l, grad_l, w0, D, batch_size=100, n_epochs=10)\n"," "]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(1, 784)\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\gnele\\AppData\\Local\\Temp\\ipykernel_10336\\1521652765.py:2: RuntimeWarning: overflow encountered in exp\n","  return 1/(1-np.exp(-x))\n"]}],"source":["M=(X_test, y_test)\n","test=(sigmoid(X_test.T@w0).T@(1-sigmoid(X_test.T@w0))*X_test@(f(w0,X_test)-y_test)).T\n","print(test.shape)\n","#print(grad_l(w0, M))"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.7 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.7"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"f7fe50f66547397f52fa8f3173b62f0a50afeece8ca887c47575661c2f678e05"}}},"nbformat":4,"nbformat_minor":2}
