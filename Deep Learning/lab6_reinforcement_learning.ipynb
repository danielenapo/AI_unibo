{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xX_FOgH79lQ6",
        "outputId": "11fa7a4a-2ff4-44fd-d08f-c24059683543"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MicroRacer'...\n",
            "remote: Enumerating objects: 264, done.\u001b[K\n",
            "remote: Counting objects: 100% (120/120), done.\u001b[K\n",
            "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
            "remote: Total 264 (delta 98), reused 84 (delta 84), pack-reused 144\u001b[K\n",
            "Receiving objects: 100% (264/264), 1.42 MiB | 10.05 MiB/s, done.\n",
            "Resolving deltas: 100% (127/127), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/asperti/MicroRacer.git\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up environment"
      ],
      "metadata": {
        "id": "eKwdolq_-4n2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "from datetime import datetime\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import backend as K\n",
        "#import tensorflow_probabilities as tpf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from MicroRacer import tracks"
      ],
      "metadata": {
        "id": "9GjRLCZC93ZB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the racer object.\n",
        "racer = tracks.Racer(obstacles=True,\n",
        "                     turn_limit=True,\n",
        "                     chicanes=True,\n",
        "                     low_speed_termination=True)\n",
        "\n",
        "# Generate a new track and get the starting state s_0\n",
        "start_state = racer.reset()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5lAk6jM_7Ku",
        "outputId": "e4367116-c59e-491f-dc90-ad64272b49ba"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initial speed =  0.4213772195111265\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Parameters\n",
        "num_states = 5 #we reduce the state dim through observation\n",
        "num_actions = 2 #acceleration and steering\n",
        "print(\"State Space dim: {}, Action Space dim: {}\".format(num_states,num_actions))\n",
        "\n",
        "upper_bound = 1\n",
        "lower_bound = -1\n",
        "print(\"Min and Max Value of Action: {}\".format(lower_bound,upper_bound))\n",
        "\n",
        "# Discount factor\n",
        "gamma = 0.99 #to give more importance to errors closer in time \n",
        "\n",
        "# Buffer settings\n",
        "buffer_dim = 50000 #useful to avoid computations when doing same operations multiple times\n",
        "batch_size = 64"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GA5aD22CAv_u",
        "outputId": "cd78586b-4bf8-4a41-cf6c-b907d04244d3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "State Space dim: 5, Action Space dim: 2\n",
            "Min and Max Value of Action: -1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DDPG (Deep Deterministic Policy Gradient)\n",
        "DDPG (Deep Deterministic Policy Gradient) is an extension of Deep Q-Learning to the continuous action-state setup. It is here implemented by an Actor-Critic setup, where the Actor takes as input the state \n",
        " and decides the action \n",
        ", while the critic takes the state \n",
        " and the action, decided by the Actor, and returns the Q-value \n",
        ".\n",
        "\n",
        "The actor is thus implemented as a Fully-Connected Neural Network, taking as imput the actual state \n",
        " and returning a tuple \n",
        ", representing the turning angle and the acceleration, respectively."
      ],
      "metadata": {
        "id": "RtMME7VvBQxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#The actor choose the move, given the state\n",
        "def get_actor(train_acceleration=True,train_direction=True):\n",
        "    # the actor has separate towers for action and speed\n",
        "    # in this way we can train them separately\n",
        "\n",
        "    inputs = layers.Input(shape=(num_states,))\n",
        "    out1 = layers.Dense(32, activation=\"relu\", trainable=train_acceleration)(inputs)\n",
        "    out1 = layers.Dense(32, activation=\"relu\", trainable=train_acceleration)(out1)\n",
        "    out1 = layers.Dense(1, activation='tanh', trainable=train_acceleration)(out1)\n",
        "\n",
        "    out2 = layers.Dense(32, activation=\"relu\", trainable=train_direction)(inputs)\n",
        "    out2 = layers.Dense(32, activation=\"relu\",trainable=train_direction)(out2)\n",
        "    out2 = layers.Dense(1, activation='tanh',trainable=train_direction)(out2)\n",
        "\n",
        "    outputs = layers.concatenate([out1,out2]) #output it's the decided actions (direction and acceleration)\n",
        "\n",
        "    #outputs = outputs * upper_bound #resize the range, if required\n",
        "    model = tf.keras.Model(inputs, outputs, name=\"actor\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "HBKckKhXBL_2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The critic computes q-value.\n",
        "\n",
        "Takes state and action, processes them separately with dense layers, concatenates the results and processes it again with 2 more dense layers, and outputs a single value with relu activation."
      ],
      "metadata": {
        "id": "28fV1hI-DAwv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The critic computes the q-value, given the state and the action (2 inputs)\n",
        "def get_critic():\n",
        "    # State as input\n",
        "    state_input = layers.Input(shape=(num_states))\n",
        "    state_out = layers.Dense(16, activation=\"relu\")(state_input)\n",
        "    state_out = layers.Dense(32, activation=\"relu\")(state_out)\n",
        "\n",
        "    # Action as input\n",
        "    action_input = layers.Input(shape=(num_actions))\n",
        "    action_out = layers.Dense(32, activation=\"relu\")(action_input)\n",
        "\n",
        "    concat = layers.Concatenate()([state_out, action_out]) #concatenates processed inputs to generate a single output\n",
        "\n",
        "    out = layers.Dense(64, activation=\"relu\")(concat)\n",
        "    out = layers.Dense(64, activation=\"relu\")(out)\n",
        "    outputs = layers.Dense(1)(out) #Outputs single value\n",
        "\n",
        "    model = tf.keras.Model([state_input, action_input], outputs, name=\"critic\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "YTkkZmwKDDDH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Actor and the Critic model can be chained together such that the output of the Actor get feeded into the input of the Critic.\n",
        "\n",
        "since q-value requires the taken action as imput, decided by the actor model (DEEP Q-LEARNING)"
      ],
      "metadata": {
        "id": "eDDi269pDFnP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#We compose actor and critic in a single model.\n",
        "#The actor is trained by maximizing the future expected reward, estimated\n",
        "#by the critic. The critic should be freezed while training the actor.\n",
        "#For simplicitly, we just use the target critic, that is not trainable.\n",
        "def compose(actor,critic):\n",
        "    state_input = layers.Input(shape=(num_states))\n",
        "    a = actor(state_input)\n",
        "    q = critic([state_input,a])\n",
        "\n",
        "    m = tf.keras.Model(state_input, q)\n",
        "    #the loss function of the compound model is just the opposite of the critic output\n",
        "    m.add_loss(-q)\n",
        "    return(m)"
      ],
      "metadata": {
        "id": "S1iGSzr4DFNb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training is performed in such a way that the Critic estimation becomes closer and closer to \n",
        "Q(s,a), while the Actor (that approximates the action of \n",
        ") approaches the optimal policy."
      ],
      "metadata": {
        "id": "OGHzKJULEYtX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating models\n",
        "actor_model = get_actor()\n",
        "critic_model = get_critic()\n",
        "\n",
        "# we create the target model for double learning (to prevent a moving target phenomenon)\n",
        "target_actor = get_actor()\n",
        "target_critic = get_critic()\n",
        "\n",
        "# make target models non trainable.\n",
        "target_actor.trainable = False\n",
        "target_critic.trainable = False\n",
        "\n",
        "# Compose the models in a single one.\n",
        "aux_model = compose(actor_model, critic_model)"
      ],
      "metadata": {
        "id": "SuhUnC7lEbxD"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the buffer"
      ],
      "metadata": {
        "id": "f2U4fX4vEmh8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Replay buffer\n",
        "class Buffer:\n",
        "    def __init__(self, buffer_capacity=100000, batch_size=64):\n",
        "        # Max Number of tuples that can be stored\n",
        "        self.buffer_capacity = buffer_capacity\n",
        "        # Num of tuples used for training\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        # Current number of tuples in buffer\n",
        "        self.buffer_counter = 0\n",
        "\n",
        "        # We have a different array for each tuple element\n",
        "        self.state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
        "        self.action_buffer = np.zeros((self.buffer_capacity, num_actions))\n",
        "        self.reward_buffer = np.zeros((self.buffer_capacity, 1))\n",
        "        self.done_buffer = np.zeros((self.buffer_capacity, 1))\n",
        "        self.next_state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
        "\n",
        "    # Stores a transition (s,a,r,s') in the buffer\n",
        "    def record(self, obs_tuple):\n",
        "        s,a,r,T,sn = obs_tuple\n",
        "        # restart form zero if buffer_capacity is exceeded, replacing old records\n",
        "        index = self.buffer_counter % self.buffer_capacity\n",
        "\n",
        "        self.state_buffer[index] = tf.squeeze(s)\n",
        "        self.action_buffer[index] = a\n",
        "        self.reward_buffer[index] = r\n",
        "        self.done_buffer[index] = T\n",
        "        self.next_state_buffer[index] = tf.squeeze(sn)\n",
        "\n",
        "        self.buffer_counter += 1\n",
        "\n",
        "    def sample_batch(self):\n",
        "        # Get sampling range\n",
        "        record_range = min(self.buffer_counter, self.buffer_capacity)\n",
        "        # Randomly sample indices\n",
        "        batch_indices = np.random.choice(record_range, self.batch_size)\n",
        "\n",
        "        s = self.state_buffer[batch_indices]\n",
        "        a = self.action_buffer[batch_indices]\n",
        "        r = self.reward_buffer[batch_indices]\n",
        "        T = self.done_buffer[batch_indices]\n",
        "        sn = self.next_state_buffer[batch_indices]\n",
        "        return ((s,a,r,T,sn))"
      ],
      "metadata": {
        "id": "qRV_B1HBEfgP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we define the policy. We use a kind of \n",
        "$ϵ$-greedy policy, where noise is added to the choice of the Actor, to favor the exploration of the Environment."
      ],
      "metadata": {
        "id": "IGnFfE-mEsb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def policy(state, verbose=False):\n",
        "    #the policy used for training just add noise to the action\n",
        "    #the amount of noise is kept constant during training\n",
        "    sampled_action = tf.squeeze(actor_model(state))\n",
        "    noise = np.random.normal(scale=0.1,size=2)\n",
        "\n",
        "    #we may change the amount of noise for actions during training\n",
        "    noise[0] *= 2\n",
        "    noise[1] *= .5\n",
        "\n",
        "    # Adding noise to action\n",
        "    sampled_action = sampled_action.numpy()\n",
        "    sampled_action += noise\n",
        "\n",
        "    #in verbose mode, we may print information about selected actions\n",
        "    if verbose and sampled_action[0] < 0:\n",
        "        print(\"decelerating\")\n",
        "\n",
        "    #Finally, we ensure actions are within bounds\n",
        "    legal_action = np.clip(sampled_action, lower_bound, upper_bound)\n",
        "\n",
        "    return [np.squeeze(legal_action)]"
      ],
      "metadata": {
        "id": "udO19aHPEyRs"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train\n",
        "Finally, we define the function that trains the model and we lunch it.\n",
        "\n"
      ],
      "metadata": {
        "id": "ccpXzsxeE1L8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "total_iterations = 50_000\n",
        "\n",
        "# Target network parameter update factor, for double DQN\n",
        "tau = 0.005\n",
        "\n",
        "# Learning rate for actor-critic models\n",
        "critic_lr = 0.001\n",
        "aux_lr = 0.001\n",
        "\n",
        "is_training = False\n",
        "\n",
        "load_weights = True\n",
        "save_weights = True\n",
        "\n",
        "weights_file_actor = \"./MicroRacer/weights/ddpg_actor_model_car\"\n",
        "weights_file_critic = \"./MicroRacer/weights/ddpg_critic_model_car\"\n",
        "\n",
        "\n",
        "\n",
        "# Slowly updating target parameters according to the tau rate <<1\n",
        "@tf.function\n",
        "def update_target(target_weights, weights, tau):\n",
        "    for (a, b) in zip(target_weights, weights):\n",
        "        a.assign(b * tau + a * (1 - tau))\n",
        "\n",
        "def update_weights(target_weights, weights, tau):\n",
        "    return(target_weights * (1- tau) +  weights * tau)\n",
        "\n",
        "\n",
        "\n",
        "## TRAINING ##\n",
        "if load_weights:\n",
        "    critic_model = keras.models.load_model(weights_file_critic)\n",
        "    actor_model = keras.models.load_model(weights_file_actor)\n",
        "\n",
        "# Making the weights equal initially\n",
        "target_actor_weights = actor_model.get_weights()\n",
        "target_critic_weights = critic_model.get_weights()\n",
        "target_actor.set_weights(target_actor_weights)\n",
        "target_critic.set_weights(target_critic_weights)\n",
        "\n",
        "# Define the optimizer\n",
        "critic_optimizer = tf.keras.optimizers.Adam(critic_lr)\n",
        "aux_optimizer = tf.keras.optimizers.Adam(aux_lr)\n",
        "\n",
        "# Compile the models\n",
        "critic_model.compile(loss='mse',optimizer=critic_optimizer)\n",
        "aux_model.compile(optimizer=aux_optimizer)\n",
        "\n",
        "# Create the buffer\n",
        "buffer = Buffer(buffer_dim, batch_size)\n",
        "\n",
        "# History of rewards per episode\n",
        "ep_reward_list = []\n",
        "# Average reward history of last few episodes\n",
        "avg_reward_list = []         \n",
        "\n",
        "# We introduce a probability of doing n empty actions to separate the environment time-step from the agent\n",
        "def step(action):\n",
        "    n = 1\n",
        "    t = np.random.randint(0,n)\n",
        "    state ,reward,done = racer.step(action)\n",
        "    for i in range(t):\n",
        "        if not done:\n",
        "            state ,t_r, done = racer.step([0, 0])\n",
        "            #state ,t_r, done =racer.step(action)\n",
        "            reward+=t_r\n",
        "    return (state, reward, done)\n",
        "\n",
        "\n",
        "def train(total_iterations=total_iterations):\n",
        "    i = 0\n",
        "    mean_speed = 0\n",
        "    ep = 0\n",
        "    avg_reward = 0\n",
        "    while i<total_iterations:\n",
        "\n",
        "        prev_state = racer.reset()\n",
        "        episodic_reward = 0\n",
        "        mean_speed += prev_state[num_states-1]\n",
        "        done = False\n",
        "        while not(done):\n",
        "            i = i+1\n",
        "            tf_prev_state = tf.expand_dims(tf.convert_to_tensor(prev_state), 0)\n",
        "            #our policy is always noisy\n",
        "            action = policy(tf_prev_state)[0]\n",
        "            # Get state and reward from the environment\n",
        "            state, reward, done = step(action)\n",
        "            \n",
        "            #we distinguish between termination with failure (state = None) and succesfull termination on track completion\n",
        "            #succesfull termination is stored as a normal tuple\n",
        "            fail = done and len(state)<num_states \n",
        "            buffer.record((prev_state, action, reward, fail, state))\n",
        "            if not(done):\n",
        "                mean_speed += state[num_states-1]\n",
        "        \n",
        "            episodic_reward += reward\n",
        "\n",
        "            if buffer.buffer_counter>batch_size:\n",
        "                states,actions,rewards,dones,newstates= buffer.sample_batch()\n",
        "                targetQ = rewards + (1-dones)*gamma*(target_critic([newstates,target_actor(newstates)]))\n",
        "                loss1 = critic_model.train_on_batch([states,actions],targetQ)\n",
        "                loss2 = aux_model.train_on_batch(states)\n",
        "\n",
        "                update_target(target_actor.variables, actor_model.variables, tau)\n",
        "                update_target(target_critic.variables, critic_model.variables, tau)\n",
        "            prev_state = state\n",
        "            \n",
        "            if i%100 == 0:\n",
        "                avg_reward_list.append(avg_reward)\n",
        "                \n",
        "\n",
        "        ep_reward_list.append(episodic_reward)\n",
        "\n",
        "        # Mean of last 40 episodes\n",
        "        avg_reward = np.mean(ep_reward_list[-40:])\n",
        "        print(\"Episode {}: Iterations {}, Avg. Reward = {}, Last reward = {}. Avg. speed = {}\".format(ep, i, avg_reward,episodic_reward,mean_speed/i))\n",
        "        print(\"\\n\")\n",
        "        \n",
        "        if ep>0 and ep%40 == 0:\n",
        "            print(\"## Evaluating policy ##\")\n",
        "            tracks.metrics_run(actor_model, 10)\n",
        "        ep += 1\n",
        "        \n",
        "\n",
        "    if total_iterations > 0:\n",
        "        if save_weights:\n",
        "            critic_model.save(weights_file_critic)\n",
        "            actor_model.save(weights_file_actor)\n",
        "        # Plotting Episodes versus Avg. Rewards\n",
        "        plt.plot(avg_reward_list)\n",
        "        plt.xlabel(\"Training steps x100\")\n",
        "        plt.ylabel(\"Avg. Episodic Reward\")\n",
        "        plt.ylim(-3.5,7)\n",
        "        plt.show(block=False)\n",
        "        plt.pause(0.001)\n",
        "        print(\"### DDPG Training ended ###\")\n",
        "        print(\"Trained over {} steps\".format(i))\n",
        "\n",
        "# Rung training\n",
        "if is_training:\n",
        "    start_t = datetime.now()\n",
        "    train()\n",
        "    end_t = datetime.now()\n",
        "    print(\"Time elapsed: {}\".format(end_t-start_t))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0kGc67NE3bD",
        "outputId": "00e9f39c-a008-4e34-f1a6-322e42e3268f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: each row is an episode (a full execution of the code).\n",
        "For each one we have a summary. When the reward gets positive, it means it compleated a track.\n",
        "\n",
        "Problem: this takes at least around 50000 iterations (very innefficient), which is hours of training!\n",
        "\n"
      ],
      "metadata": {
        "id": "Sip2FTTXFoln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The model we will use to compete is the Actor model\n",
        "ddpg_model = actor_model"
      ],
      "metadata": {
        "id": "xqb12NkmE8x7"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DDPG2\n",
        "\n",
        "As already mentioned, DDPG2 is a variant of DDPG where noise is added to the parameter to stabilize training. The implementation is basically the same we used for DDPG."
      ],
      "metadata": {
        "id": "BTxm8ZluHDXA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "total_iterations = 50000\n",
        "\n",
        "# Discount factor\n",
        "gamma = 0.99\n",
        "\n",
        "# Target network parameter update factor, for double DQN\n",
        "tau = 0.005\n",
        "\n",
        "# Learning rate for actor-critic models\n",
        "critic_lr = 0.001\n",
        "aux_lr = 0.001\n",
        "\n",
        "param_noise_stddev = 0.2\n",
        "\n",
        "is_training = False\n",
        "\n",
        "load_weights = True\n",
        "save_weights = True #beware when saving weights to not overwrite previous data\n",
        "\n",
        "weights_file_actor = \"MicroRacer/weights/ddpg2_actor_model_car\"\n",
        "weights_file_critic = \"MicroRacer/weights/ddpg2_critic_model_car\"\n",
        "\n",
        "\n",
        "#The actor choose the move, given the state\n",
        "def get_actor():\n",
        "\n",
        "    inputs = layers.Input(shape=(num_states,))\n",
        "    out = layers.Dense(64, name=\"perturbable1\", activation=\"relu\")(inputs)\n",
        "    out = layers.LayerNormalization()(out)\n",
        "    out = layers.Dense(64, name=\"perturbable2\", activation=\"relu\")(out)\n",
        "    out = layers.LayerNormalization()(out)\n",
        "    outputs = layers.Dense(num_actions, name=\"perturbable3\", activation=\"tanh\")(out)\n",
        "\n",
        "    model = tf.keras.Model(inputs, outputs, name=\"actor\")\n",
        "    return model\n",
        "    \n",
        "\n",
        "#the critic compute the q-value, given the state and the action\n",
        "def get_critic():\n",
        "    # State as input\n",
        "    state_input = layers.Input(shape=(num_states))\n",
        "    state_out = layers.Dense(16, activation=\"relu\")(state_input)\n",
        "    state_out = layers.Dense(32, activation=\"relu\")(state_out)\n",
        "\n",
        "    # Action as input\n",
        "    action_input = layers.Input(shape=(num_actions))\n",
        "    action_out = layers.Dense(32, activation=\"relu\")(action_input)\n",
        "\n",
        "    concat = layers.Concatenate()([state_out, action_out])\n",
        "\n",
        "    out = layers.Dense(64, activation=\"relu\")(concat)\n",
        "    out = layers.Dense(64, activation=\"relu\")(out)\n",
        "    outputs = layers.Dense(1)(out) #Outputs single value\n",
        "\n",
        "    model = tf.keras.Model([state_input, action_input], outputs, name=\"critic\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "#creating models\n",
        "actor_model = get_actor()\n",
        "critic_model = get_critic()\n",
        "\n",
        "#we create the target model for double learning (to prevent a moving target phenomenon)\n",
        "target_actor = get_actor()\n",
        "target_critic = get_critic()\n",
        "target_actor.trainable = False\n",
        "target_critic.trainable = False\n",
        "\n",
        "#We compose actor and critic in a single model.\n",
        "#The actor is trained by maximizing the future expected reward, estimated\n",
        "#by the critic. The critic should be freezed while training the actor.\n",
        "#For simplicitly, we just use the target critic, that is not trainable.\n",
        "def compose(actor,critic):\n",
        "    state_input = layers.Input(shape=(num_states))\n",
        "    a = actor(state_input)\n",
        "    q = critic([state_input,a])\n",
        "    #reg_weights = actor.get_layer('out').get_weights()[0]\n",
        "    #print(tf.reduce_sum(0.01 * tf.square(reg_weights)))\n",
        "\n",
        "    m = tf.keras.Model(state_input, q)\n",
        "    #the loss function of the compound model is just the opposite of the critic output\n",
        "    m.add_loss(-q)\n",
        "    return(m)\n",
        "\n",
        "\n",
        "\n",
        "## ONLY MODIFICATION TO DDPG:\n",
        "# Updates weigths of the perturbed actor inserting noise too\n",
        "def get_perturbed_actor_updates(actor, perturbed_actor, param_noise_stddev):\n",
        "    updates = []\n",
        "    for var, perturbed_var in zip(actor.trainable_variables, perturbed_actor.trainable_variables):\n",
        "        if \"perturbable\" in var.name:\n",
        "            updates.append(perturbed_var.assign( var + tf.random.normal(tf.shape(var), mean=0., stddev=param_noise_stddev)))\n",
        "    return tf.group(*updates)\n",
        "\n",
        "# Calculates distance between perturbed actor and clean actor and uses it to update standard deviation\n",
        "def adapt_param_noise(actor, adaptive_actor, states,current_stddev):\n",
        "    adoption_coefficient=1.01\n",
        "    # Perturb a separate copy of the policy to adjust the scale for the next \"real\" perturbation.\n",
        "    perturb_adaptive_policy_ops = get_perturbed_actor_updates(actor, adaptive_actor, current_stddev)\n",
        "    distance = tf.sqrt(tf.reduce_mean(tf.square(actor(states) - adaptive_actor(states))))\n",
        "    \n",
        "    if distance > current_stddev:\n",
        "        # Decrease stddev.\n",
        "        current_stddev /= adoption_coefficient\n",
        "    else:\n",
        "        # Increase stddev.\n",
        "        current_stddev *= adoption_coefficient\n",
        "    return current_stddev\n",
        "\n",
        "aux_model = compose(actor_model,target_critic)\n",
        "\n",
        "# Configure perturbed actor.\n",
        "param_noise_actor = get_actor()\n",
        "perturb_policy_ops = get_perturbed_actor_updates(actor_model, param_noise_actor, param_noise_stddev)\n",
        "\n",
        "# Configure separate copy for stddev adoption.\n",
        "adaptive_param_noise_actor = get_actor()\n",
        "perturb_adaptive_policy_ops = get_perturbed_actor_updates(actor_model, adaptive_param_noise_actor, param_noise_stddev)"
      ],
      "metadata": {
        "id": "LMacDoo3HJyI"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Replay buffer\n",
        "class Buffer:\n",
        "    def __init__(self, buffer_capacity=100000, batch_size=64):\n",
        "        # Max Number of tuples that can be stored\n",
        "        self.buffer_capacity = buffer_capacity\n",
        "        # Num of tuples used for training\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        # Current number of tuples in buffer\n",
        "        self.buffer_counter = 0\n",
        "\n",
        "        # We have a different array for each tuple element\n",
        "        self.state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
        "        self.action_buffer = np.zeros((self.buffer_capacity, num_actions))\n",
        "        self.reward_buffer = np.zeros((self.buffer_capacity, 1))\n",
        "        self.done_buffer = np.zeros((self.buffer_capacity, 1))\n",
        "        self.next_state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
        "\n",
        "    # Stores a transition (s,a,r,s') in the buffer\n",
        "    def record(self, obs_tuple):\n",
        "        s,a,r,T,sn = obs_tuple\n",
        "        # restart form zero if buffer_capacity is exceeded, replacing old records\n",
        "        index = self.buffer_counter % self.buffer_capacity\n",
        "\n",
        "        self.state_buffer[index] = tf.squeeze(s)\n",
        "        self.action_buffer[index] = a\n",
        "        self.reward_buffer[index] = r\n",
        "        self.done_buffer[index] = T\n",
        "        self.next_state_buffer[index] = tf.squeeze(sn)\n",
        "\n",
        "        self.buffer_counter += 1\n",
        "\n",
        "    def sample_batch(self):\n",
        "        # Get sampling range\n",
        "        record_range = min(self.buffer_counter, self.buffer_capacity)\n",
        "        # Randomly sample indices\n",
        "        batch_indices = np.random.choice(record_range, self.batch_size)\n",
        "\n",
        "        s = self.state_buffer[batch_indices]\n",
        "        a = self.action_buffer[batch_indices]\n",
        "        r = self.reward_buffer[batch_indices]\n",
        "        T = self.done_buffer[batch_indices]\n",
        "        sn = self.next_state_buffer[batch_indices]\n",
        "        return ((s,a,r,T,sn))\n",
        "\n",
        "buffer = Buffer(buffer_dim, batch_size)"
      ],
      "metadata": {
        "id": "RB_26p4tHLxU"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Slowly updating target parameters according to the tau rate <<1\n",
        "@tf.function\n",
        "def update_target(target_weights, weights, tau):\n",
        "    for (a, b) in zip(target_weights, weights):\n",
        "        a.assign(b * tau + a * (1 - tau))\n",
        "\n",
        "def update_weights(target_weights, weights, tau):\n",
        "    return(target_weights * (1- tau) +  weights * tau)\n",
        "\n",
        "def policy(state,verbose=False):\n",
        "    add_action_noise = False\n",
        "    # we use the actor modified with parametric noise to generate the action\n",
        "    sampled_action = tf.squeeze(param_noise_actor(state))\n",
        "    if add_action_noise:\n",
        "        noise = np.random.normal(scale=0.1,size=2)\n",
        "        #we may change the amount of noise for actions during training\n",
        "        noise[0] *= 2\n",
        "        noise[1] *= .5\n",
        "        # Adding noise to action\n",
        "        sampled_action = sampled_action.numpy()\n",
        "        sampled_action += noise\n",
        "    #in verbose mode, we may print information about selected actions\n",
        "    if verbose and sampled_action[0] < 0:\n",
        "        print(\"decelerating\")\n",
        "\n",
        "    #Finally, we ensure actions are within bounds\n",
        "    legal_action = np.clip(sampled_action, lower_bound, upper_bound)\n",
        "\n",
        "    return [np.squeeze(legal_action)]\n",
        "\n",
        "\n",
        "## TRAINING ##\n",
        "if load_weights:\n",
        "    critic_model = keras.models.load_model(weights_file_critic)\n",
        "    actor_model = keras.models.load_model(weights_file_actor)\n",
        "\n",
        "# Making the weights equal initially\n",
        "target_actor_weights = actor_model.get_weights()\n",
        "target_critic_weights = critic_model.get_weights()\n",
        "target_actor.set_weights(target_actor_weights)\n",
        "target_critic.set_weights(target_critic_weights)\n",
        "\n",
        "\n",
        "\n",
        "critic_model.compile(loss='mse',optimizer=tf.keras.optimizers.Adam(critic_lr))\n",
        "aux_model.compile(optimizer=tf.keras.optimizers.Adam(aux_lr))\n",
        "\n",
        "\n",
        "# History of rewards per episode\n",
        "ep_reward_list = []\n",
        "# Average reward history of last few episodes\n",
        "avg_reward_list = []\n",
        "\n",
        "\n",
        "# We introduce a probability of doing n empty actions to separate the environment time-step from the agent   \n",
        "def step(action):\n",
        "    n = 1\n",
        "    t = np.random.randint(0,n)\n",
        "    state ,reward,done = racer.step(action)\n",
        "    for i in range(t):\n",
        "        if not done:\n",
        "            state ,t_r, done =racer.step([0, 0])\n",
        "            #state ,t_r, done =racer.step(action)\n",
        "            reward+=t_r\n",
        "    return (state, reward, done)\n",
        "\n",
        "\n",
        "def train(total_iterations=total_iterations):\n",
        "    i = 0\n",
        "    mean_speed = 0\n",
        "    current_stddev = param_noise_stddev\n",
        "    ep = 0\n",
        "    avg_reward = 0\n",
        "    while i<total_iterations:\n",
        "        prev_state = racer.reset()\n",
        "        episodic_reward = 0\n",
        "        mean_speed += prev_state[4]\n",
        "        done = False\n",
        "        while not(done):\n",
        "            i = i+1\n",
        "            tf_prev_state = tf.expand_dims(tf.convert_to_tensor(prev_state), 0)\n",
        "            #our policy is always noisy\n",
        "            action = policy(tf_prev_state)[0]\n",
        "            # Get state and reward from the environment\n",
        "            state, reward, done = step(action)\n",
        "            \n",
        "            #we distinguish between termination with failure (state = None) and succesfull termination on track completion\n",
        "            #succesfull termination is stored as a normal tuple\n",
        "            fail = done and len(state)<5 \n",
        "            buffer.record((prev_state, action, reward, fail, state))\n",
        "            if not(done):\n",
        "                mean_speed += state[4]\n",
        "        \n",
        "            episodic_reward += reward\n",
        "\n",
        "            if buffer.buffer_counter>batch_size:\n",
        "                states,actions,rewards,dones,newstates= buffer.sample_batch()\n",
        "                targetQ = rewards + (1-dones)*gamma*(target_critic([newstates,target_actor(newstates)]))\n",
        "                loss1 = critic_model.train_on_batch([states,actions],targetQ)\n",
        "                loss2 = aux_model.train_on_batch(states)\n",
        "\n",
        "                update_target(target_actor.variables, actor_model.variables, tau)\n",
        "                update_target(target_critic.variables, critic_model.variables, tau)\n",
        "                \n",
        "                # We calculate adapted standard devation at every step\n",
        "                current_stddev = adapt_param_noise(actor_model, adaptive_param_noise_actor, states,current_stddev)\n",
        "            prev_state = state\n",
        "            \n",
        "            if i%100 == 0:\n",
        "                avg_reward_list.append(avg_reward)\n",
        "        \n",
        "        # We update the perturbed actor parametric noise only after an episode\n",
        "        perturb_policy_ops = get_perturbed_actor_updates(actor_model, param_noise_actor, current_stddev)\n",
        "\n",
        "        ep_reward_list.append(episodic_reward)\n",
        "\n",
        "        # Mean of last 40 episodes\n",
        "        avg_reward = np.mean(ep_reward_list[-40:])\n",
        "        print(\"Episode {}: Iterations {}, Avg. Reward = {}, Last reward = {}. Avg. speed = {}\".format(ep, i, avg_reward,episodic_reward,mean_speed/i))\n",
        "        print(\"\\n\")\n",
        "        \n",
        "        if ep>0 and ep%40 == 0:\n",
        "            print(\"## Evaluating policy ##\")\n",
        "            tracks.metrics_run(actor_model, 10)\n",
        "        ep += 1\n",
        "\n",
        "    if total_iterations > 0:\n",
        "        if save_weights:\n",
        "            critic_model.save(weights_file_critic)\n",
        "            actor_model.save(weights_file_actor)\n",
        "        # Plotting Episodes versus Avg. Rewards\n",
        "        plt.plot(avg_reward_list)\n",
        "        plt.xlabel(\"Training steps x100\")\n",
        "        plt.ylabel(\"Avg. Episodic Reward\")\n",
        "        plt.ylim(-3.5,7)\n",
        "        plt.show(block=False)\n",
        "        plt.pause(0.001)\n",
        "        print(\"### DDPG2 Training ended ###\")\n",
        "        print(\"Trained over {} steps\".format(i))\n",
        "\n",
        "if is_training:\n",
        "    start_t = datetime.now()\n",
        "    train()\n",
        "    end_t = datetime.now()\n",
        "    print(\"Time elapsed: {}\".format(end_t-start_t))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyLQjeLtHVkE",
        "outputId": "eacb80dc-0f93-4b72-adb5-772899bf022d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To compete, we will be use the actor model\n",
        "ddpg2_model = actor_model"
      ],
      "metadata": {
        "id": "MQ9ZvuubHZKT"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PPO (Proximal Policy Optimization)\n",
        "\n",
        "PPO is a policy-gradient technique, i.e. where we assume the policy to be continuous and we explicitely train on it. Its main difference w.r.t. classical policy-gradient methods is that it clips the objective function to ensure that the deviation from the previous policy is relatively small. The differences with the other two models, in terms of code, are negligible.\n",
        "\n",
        "Note that here the Actor does not returns the action to perform, but the mean and the standard deviation of the Gaussian distribution defining the action to consider. In particular, the actor \n",
        " here models Gaussian distribution N(at|A(st))\n",
        " instead of explicitly generates an action \n",
        ". The training code is easier since we are forced to use the tensorflow_probability package, which does the biggest portion of the job authomatically."
      ],
      "metadata": {
        "id": "OMEm8j55HewM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#actor just returns mean and variance. the critic samples actions from it\n",
        "#The actor choose the move, given the state\n",
        "class Get_actor(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.d1 = layers.Dense(64, activation=\"tanh\")\n",
        "        self.d2 = layers.Dense(64, activation=\"tanh\")\n",
        "        self.m = layers.Dense(num_actions, activation=\"tanh\")\n",
        "        \n",
        "    def call(self, s):\n",
        "        out = self.d1(s)\n",
        "        out = self.d2(out)\n",
        "        mu = self.m(out)\n",
        "        sigma = 0.2\n",
        "        return  mu, sigma\n",
        "    \n",
        "    @property  \n",
        "    def trainable_variables(self):\n",
        "        return self.d1.trainable_variables + \\\n",
        "                self.d2.trainable_variables + \\\n",
        "                self.m.trainable_variables\n",
        "\n",
        "\n",
        "#the critic compute the value, given the state \n",
        "class Get_critic(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.d1 = layers.Dense(64, activation=\"tanh\")\n",
        "        self.d2 = layers.Dense(64, activation=\"tanh\")\n",
        "        self.o = layers.Dense(1)\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        out = self.d1(inputs)\n",
        "        out = self.d2(out)\n",
        "        q = self.o(out)\n",
        "        return q\n",
        "    \n",
        "    @property\n",
        "    def trainable_variables(self):\n",
        "        return self.d1.trainable_variables + \\\n",
        "                self.d2.trainable_variables + \\\n",
        "                self.o.trainable_variables\n",
        "\n",
        "class Agent:\n",
        "    def __init__(self):\n",
        "        self.racer = tracks.Racer()\n",
        "        self.actor_model = Get_actor()\n",
        "        self.critic_model = Get_critic()\n",
        "        self.buffer = Buffer(batch_size)     \n",
        "        ## TRAINING ##\n",
        "        self.critic_model(layers.Input(shape=(num_states)))\n",
        "        self.actor_model(layers.Input(shape=(num_states)))\n",
        "        if load_weights:\n",
        "            self.critic_model = keras.models.load_model(weights_file_critic)\n",
        "            self.actor_model = keras.models.load_model(weights_file_actor)\n",
        "        self.actor_optimizer = tf.keras.optimizers.Adam(actor_lr)\n",
        "        self.critic_optimizer = tf.keras.optimizers.Adam(critic_lr)\n",
        "        self.actor_model.compile(optimizer=self.actor_optimizer)\n",
        "        self.critic_model.compile(loss=\"mse\",optimizer=self.critic_optimizer)\n",
        "        # History of rewards per episode\n",
        "        self.ep_reward_list = []\n",
        "        # Average reward history of last few episodes\n",
        "        self.avg_reward_list = []\n",
        "        # Keep track of how many training steps has been done\n",
        "        \n",
        "    #Returns an action sampled from the normal distribution returned by the actor and it's relative log probability.\n",
        "    #If an action is passed returns it's log probability.\n",
        "    def get_action_and_logp(self, states, actions=None):\n",
        "        mu, sigma = self.actor_model(states)\n",
        "        dist = tfp.distributions.Normal(mu, sigma)\n",
        "        if actions is None:\n",
        "            # Use of the reparameterization trick \n",
        "            actions = mu + sigma * tfp.distributions.Normal(0,1).sample(num_actions)   \n",
        "        log_p = dist.log_prob(actions)\n",
        "        \n",
        "        if len(log_p.shape)>1:\n",
        "            log_p = tf.reduce_sum(log_p,1)\n",
        "        else:\n",
        "            log_p = tf.reduce_sum(log_p)\n",
        "        log_p = tf.expand_dims(log_p, 1)\n",
        "        \n",
        "        valid_action  = K.clip(actions, lower_bound, upper_bound)\n",
        "        \n",
        "        return  valid_action, log_p\n",
        "        \n",
        "        \n",
        "    def gae(self, values, rewards, masks, lastvalue):\n",
        "        returns = []\n",
        "        gae = 0\n",
        "        for i in reversed(range(len(rewards))):\n",
        "            if i==len(rewards)-1:\n",
        "                nextvalue=lastvalue\n",
        "            else:\n",
        "                nextvalue=values[i+1]\n",
        "            delta=rewards[i]+gamma*nextvalue*masks[i]-values[i]  \n",
        "            gae=delta+gamma*gae_lambda*masks[i]*gae\n",
        "            returns.insert(0, gae+values[i])\n",
        "        advantages = returns - values\n",
        "        advantages = (advantages - tf.reduce_mean(advantages)) / (tf.math.reduce_std(advantages) + 1e-8)\n",
        "        return np.array(returns), advantages\n",
        "    \n",
        "    def update_networks(self, last_value=0): \n",
        "        states, actions, rewards, dones, values, old_logp, batches = self.buffer.sample_batch()\n",
        "        returns, advantages = self.gae(values, rewards, dones, last_value)     \n",
        "        # Train using mini-batches\n",
        "        for batch in batches:\n",
        "            s_batch = tf.convert_to_tensor(states[batch], dtype=tf.float32)\n",
        "            a_batch = tf.convert_to_tensor(actions[batch], dtype=tf.float32)\n",
        "            adv_batch = tf.expand_dims(tf.convert_to_tensor(advantages.numpy()[batch], dtype=tf.float32),1)\n",
        "            ret_batch =  tf.expand_dims(tf.convert_to_tensor(returns[batch], dtype=tf.float32),1)\n",
        "            ologp_batch = tf.expand_dims(tf.convert_to_tensor(old_logp[batch], dtype=tf.float32),1)\n",
        "            for e in range(epochs):\n",
        "                with tf.GradientTape() as tape:\n",
        "                    tape.watch(self.actor_model.trainable_variables)\n",
        "                    _,logp_batch = self.get_action_and_logp(tf.stack(s_batch), tf.stack(a_batch)) \n",
        "                    ratio = tf.exp(logp_batch-ologp_batch)\n",
        "                    weighted_ratio = ratio*adv_batch\n",
        "                    weighted_clipped_ratio = tf.clip_by_value(ratio, clip_value_min=1- policy_clip, clip_value_max=1+ policy_clip)*adv_batch\n",
        "                    min_wr = tf.minimum(weighted_ratio, weighted_clipped_ratio)- target_entropy*logp_batch\n",
        "                    loss = -tf.reduce_mean(min_wr)            \n",
        "                grad = tape.gradient(loss, self.actor_model.trainable_variables)    \n",
        "                self.actor_model.optimizer.apply_gradients(zip(grad, self.actor_model.trainable_variables))\n",
        "                \n",
        "                c_loss = self.critic_model.train_on_batch(s_batch,ret_batch)\n",
        "                \n",
        "                # We use approximatation of Kullback–Leibler divergence to early stop training epochs\n",
        "                _,logp = self.get_action_and_logp(s_batch, a_batch) \n",
        "                kl = tf.reduce_mean(ologp_batch-logp)\n",
        "                if kl > 1.5*target_kl:\n",
        "                    print(\"early stopping - max kl reached at epoch {}\".format(e))\n",
        "                    break\n",
        "\n",
        "        # We empty the buffer after policy update\n",
        "        self.buffer.clear()\n",
        "     \n",
        "    # We introduce a probability of doing n empty actions to separate the environment time-step from the agent   \n",
        "    def step(self, action):\n",
        "        n = 2\n",
        "        t = np.random.randint(0,n)\n",
        "        state ,reward,done = self.racer.step(action)\n",
        "        for i in range(t):\n",
        "            if not done:\n",
        "                state ,t_r, done = self.racer.step([0, 0])\n",
        "                #state ,t_r, done =racer.step(action)\n",
        "                reward+=t_r\n",
        "        return (state, reward, done)\n",
        "          \n",
        "    def train(self):\n",
        "        i = 0\n",
        "        mean_speed = 0\n",
        "        for ep in range(total_iterations):\n",
        "            state = self.racer.reset()\n",
        "            done = False\n",
        "            episodic_reward = 0\n",
        "            \n",
        "            while not done:    \n",
        "                i+=1\n",
        "                state = tf.expand_dims(tf.convert_to_tensor(state), 0)\n",
        "                action, logp = self.get_action_and_logp(state)\n",
        "                value = self.critic_model(state)\n",
        "                #action = K.clip(action, lower_bound, upper_bound)\n",
        "                action = tf.squeeze(action)\n",
        "                nstate, reward, done = self.step(action)\n",
        "                self.buffer.record(state, action, reward, not done, value, logp)\n",
        "                if not done:\n",
        "                    mean_speed += nstate[4]\n",
        "                state = nstate\n",
        "                episodic_reward += reward\n",
        "              \n",
        "            # training after a complete episode \n",
        "            self.update_networks()\n",
        "               \n",
        "            self.ep_reward_list.append(episodic_reward) \n",
        "            avg_reward = np.mean(self.ep_reward_list[-40:])\n",
        "            #avg_reward = np.mean(self.ep_reward_list)\n",
        "            print(\"Episode {}: Avg. Reward = {}, Last reward = {}. Avg. speed = {}\".format(ep, avg_reward,episodic_reward,mean_speed/i))\n",
        "            print(\"\\n\")\n",
        "            self.avg_reward_list.append(avg_reward)\n",
        "\n",
        "        if total_iterations > 0:\n",
        "            if save_weights:\n",
        "                self.critic_model.save(weights_file_critic)\n",
        "                self.actor_model.save(weights_file_actor)\n",
        "            # Plotting Episodes versus Avg. Rewards\n",
        "            plt.plot(self.avg_reward_list)\n",
        "            plt.xlabel(\"Episode\")\n",
        "            plt.ylabel(\"Avg. Episodic Reward\")\n",
        "            plt.ylim(-3.5,7)\n",
        "            plt.show(block=False)\n",
        "            plt.pause(0.001)\n",
        "        print(\"### PPO Training ended ###\")\n",
        "            \n",
        "\n",
        "    def launch(self):\n",
        "        if is_training:\n",
        "            start_t = datetime.now()\n",
        "            self.train()\n",
        "            end_t = datetime.now()\n",
        "            print(\"Time elapsed: {}\".format(end_t-start_t))"
      ],
      "metadata": {
        "id": "6qrT_4hXHt0h"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Learning rate for actor-critic models\n",
        "critic_lr = 3e-4\n",
        "actor_lr = 3e-4\n",
        "\n",
        "# Number of episodes\n",
        "total_iterations = 600\n",
        "\n",
        "# Mini-batch size for training\n",
        "batch_size = 64\n",
        "\n",
        "# Number of training steps with the same episode\n",
        "epochs = 10\n",
        "\n",
        "gamma = 0.99\n",
        "gae_lambda = 0.95\n",
        "policy_clip = tf.constant(0.25, dtype=tf.float32)\n",
        "\n",
        "target_entropy = tf.constant(0.01, dtype=tf.float32)\n",
        "\n",
        "target_kl = 0.01\n",
        "\n",
        "is_training = False\n",
        "\n",
        "load_weights = True\n",
        "save_weights = True\n",
        "\n",
        "weights_file_actor = \"MicroRacer/weights/ppo_actor_model_car\"\n",
        "weights_file_critic = \"MicroRacer/weights/ppo_critic_model_car\"\n",
        "        \n",
        "ppo_agent = Agent()\n",
        "ppo_agent.launch()"
      ],
      "metadata": {
        "id": "a55m80SFH6nI"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To compete, we will use the actor model\n",
        "ppo_model = ppo_agent.actor_model"
      ],
      "metadata": {
        "id": "UW_wH4XRH-GE"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SAC (Soft Actor-Critic)\n",
        "SAC (Soft Actor-Critic) is a variant of DDPG where the loss function is regularized by adding Entropy."
      ],
      "metadata": {
        "id": "MFXvhrrAIDhk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#The actor choose the move, given the state\n",
        "class Get_actor(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.d1 = layers.Dense(64, activation=\"relu\")\n",
        "        self.d2 = layers.Dense(64, activation=\"relu\")\n",
        "        self.m = layers.Dense(num_actions)\n",
        "        self.s = layers.Dense(num_actions)\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        out = self.d1(inputs)\n",
        "        out = self.d2(out)\n",
        "        mu = self.m(out)\n",
        "        log_sigma = self.s(out)\n",
        "        sigma = tf.exp(log_sigma)\n",
        "        \n",
        "        dist = tfp.distributions.Normal(mu, sigma)\n",
        "        #action = dist.sample() \n",
        "        action = mu + sigma * tfp.distributions.Normal(0,1).sample(num_actions)     \n",
        "        valid_action = tf.tanh(action)\n",
        "        \n",
        "        log_p = dist.log_prob(action)\n",
        "        #correct log_p after the tanh squashing on action \n",
        "        log_p = log_p - tf.reduce_sum(tf.math.log(1 - valid_action**2 + 1e-16), axis=1, keepdims=True)\n",
        "        \n",
        "        if len(log_p.shape)>1:\n",
        "            log_p = tf.reduce_sum(log_p,1)\n",
        "        else:\n",
        "            log_p = tf.reduce_sum(log_p)\n",
        "        log_p = tf.reshape(log_p,(-1,1))  \n",
        "        \n",
        "        eval_action = tf.tanh(mu)\n",
        "        \n",
        "        return eval_action, valid_action, log_p\n",
        "    \n",
        "    @property  \n",
        "    def trainable_variables(self):\n",
        "        return self.d1.trainable_variables + \\\n",
        "                self.d2.trainable_variables + \\\n",
        "                self.m.trainable_variables + \\\n",
        "                self.s.trainable_variables\n",
        "\n",
        "\n",
        "#the critic compute the q-value, given the state and the action\n",
        "class Get_critic(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.d1 = layers.Dense(64, activation=\"relu\")\n",
        "        self.d2 = layers.Dense(64, activation=\"relu\")\n",
        "        self.o = layers.Dense(1)\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        state, action = inputs\n",
        "        state_action = tf.concat([state, action], axis=1)\n",
        "        out = self.d1(state_action)\n",
        "        out = self.d2(out)\n",
        "        q = self.o(out)\n",
        "        return q\n",
        "    \n",
        "    @property\n",
        "    def trainable_variables(self):\n",
        "        return self.d1.trainable_variables + \\\n",
        "                self.d2.trainable_variables + \\\n",
        "                self.o.trainable_variables\n",
        "\n",
        "\n",
        "#creating models\n",
        "actor_model = Get_actor()\n",
        "critic_model = Get_critic()\n",
        "critic2_model = Get_critic()\n",
        "\n",
        "#we create the target model for double learning (to prevent a moving target phenomenon)\n",
        "target_critic = Get_critic()\n",
        "target_critic2 = Get_critic()\n",
        "target_critic.trainable = False\n",
        "target_critic2.trainable = False"
      ],
      "metadata": {
        "id": "h38NteMVIDUD"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Replay buffer\n",
        "class Buffer:\n",
        "    def __init__(self, buffer_capacity=100000, batch_size=64):\n",
        "        # Max Number of tuples that can be stored\n",
        "        self.buffer_capacity = buffer_capacity\n",
        "        # Num of tuples used for training\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        # Current number of tuples in buffer\n",
        "        self.buffer_counter = 0\n",
        "\n",
        "        # We have a different array for each tuple element\n",
        "        self.state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
        "        self.action_buffer = np.zeros((self.buffer_capacity, num_actions))\n",
        "        self.reward_buffer = np.zeros((self.buffer_capacity, 1))\n",
        "        self.done_buffer = np.zeros((self.buffer_capacity, 1))\n",
        "        self.next_state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
        "\n",
        "    # Stores a transition (s,a,r,s') in the buffer\n",
        "    def record(self, obs_tuple):\n",
        "        s,a,r,T,sn = obs_tuple\n",
        "        # restart form zero if buffer_capacity is exceeded, replacing old records\n",
        "        index = self.buffer_counter % self.buffer_capacity\n",
        "\n",
        "        self.state_buffer[index] = tf.squeeze(s)\n",
        "        self.action_buffer[index] = a\n",
        "        self.reward_buffer[index] = r\n",
        "        self.done_buffer[index] = T\n",
        "        self.next_state_buffer[index] = tf.squeeze(sn)\n",
        "\n",
        "        self.buffer_counter += 1\n",
        "\n",
        "    def sample_batch(self):\n",
        "        # Get sampling range\n",
        "        record_range = min(self.buffer_counter, self.buffer_capacity)\n",
        "        # Randomly sample indices\n",
        "        batch_indices = np.random.choice(record_range, self.batch_size)\n",
        "\n",
        "        s = self.state_buffer[batch_indices]\n",
        "        a = self.action_buffer[batch_indices]\n",
        "        r = self.reward_buffer[batch_indices]\n",
        "        T = self.done_buffer[batch_indices]\n",
        "        sn = self.next_state_buffer[batch_indices]\n",
        "        return ((s,a,r,T,sn))\n",
        "\n",
        "buffer = Buffer(buffer_dim, batch_size)"
      ],
      "metadata": {
        "id": "XreclAg8IA_c"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_probability as tfp\n",
        "# Adaptive Entropy to maximize exploration\n",
        "target_entropy = -tf.constant(num_actions, dtype=tf.float32)\n",
        "log_alpha = tf.Variable(0.0, dtype=tf.float32)\n",
        "alpha = tfp.util.DeferredTensor(log_alpha, tf.exp)\n",
        "\n",
        "is_training = False\n",
        "\n",
        "#pesi\n",
        "load_weights = True\n",
        "save_weights = False #beware when saving weights to not overwrite previous data\n",
        "\n",
        "weights_file_actor = \"MicroRacer/weights/sac_actor_model_car\"\n",
        "weights_file_critic = \"MicroRacer/weights/sac_critic_model_car\"\n",
        "weights_file_critic2 = \"MicroRacer/weights/sac_critic2_model_car\"\n",
        "\n",
        "# Learning rate for actor-critic models\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "# Slowly updating target parameters according to the tau rate <<1\n",
        "@tf.function\n",
        "def update_target(target_weights, weights, tau):\n",
        "    for (a, b) in zip(target_weights, weights):\n",
        "        a.assign(b * tau + a * (1 - tau))\n",
        "\n",
        "def update_weights(target_weights, weights, tau):\n",
        "    return(target_weights * (1- tau) +  weights * tau)\n",
        "\n",
        "## TRAINING ##\n",
        "if load_weights:\n",
        "    target_critic([layers.Input(shape=(num_states)),layers.Input(shape=(num_actions))])\n",
        "    target_critic2([layers.Input(shape=(num_states)),layers.Input(shape=(num_actions))])\n",
        "    critic_model = keras.models.load_model(weights_file_critic)\n",
        "    critic2_model = keras.models.load_model(weights_file_critic2)\n",
        "    actor_model = keras.models.load_model(weights_file_actor)\n",
        "\n",
        "# Making the weights equal initially\n",
        "target_critic_weights = critic_model.get_weights()\n",
        "target_critic2_weights = critic2_model.get_weights()\n",
        "target_critic.set_weights(target_critic_weights)\n",
        "target_critic2.set_weights(target_critic2_weights)\n",
        "\n",
        "actor_optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "critic_optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "critic2_optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "alpha_optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "\n",
        "critic_model.compile(optimizer=critic_optimizer)\n",
        "critic2_model.compile(optimizer=critic2_optimizer)\n",
        "actor_model.compile(optimizer=actor_optimizer)\n",
        "\n",
        "# History of rewards per episode\n",
        "ep_reward_list = []\n",
        "# Average reward history of last few episodes\n",
        "avg_reward_list = []\n",
        "\n",
        "# We introduce a probability of doing n empty actions to separate the environment time-step from the agent   \n",
        "def step(action):\n",
        "    n = 1\n",
        "    t = np.random.randint(0,n)\n",
        "    action = tf.squeeze(action)\n",
        "    state ,reward,done = racer.step(action)\n",
        "    for i in range(t):\n",
        "        if not done:\n",
        "            state ,t_r, done =racer.step([0, 0])\n",
        "            #state ,t_r, done =racer.step(action)\n",
        "            reward+=t_r\n",
        "    return (state, reward, done)\n",
        "\n",
        "@tf.function \n",
        "def update_critics(states, actions, rewards, dones, newstates):\n",
        "    entropy_scale = tf.convert_to_tensor(alpha)\n",
        "    _, new_policy_actions, log_probs = actor_model(newstates)\n",
        "    q1_t = target_critic([newstates, new_policy_actions])\n",
        "    q2_t = target_critic2([newstates, new_policy_actions])                    \n",
        "    tcritic_v = tf.reduce_min([q1_t,q2_t],axis=0) \n",
        "    newvalue = tcritic_v-entropy_scale*log_probs\n",
        "    q_hat = tf.stop_gradient(rewards + gamma*newvalue*(1-dones))\n",
        "    with tf.GradientTape(persistent=True) as tape1:\n",
        "        q1 = critic_model([states, actions])\n",
        "        q2 = critic2_model([states, actions]) \n",
        "        loss_c1 = tf.reduce_mean((q1 - q_hat)**2)\n",
        "        loss_c2 = tf.reduce_mean((q2 - q_hat)**2)\n",
        "    critic1_gradient = tape1.gradient(loss_c1, critic_model.trainable_variables)\n",
        "    critic2_gradient = tape1.gradient(loss_c2, critic2_model.trainable_variables)\n",
        "    critic_model.optimizer.apply_gradients(zip(critic1_gradient, critic_model.trainable_variables))\n",
        "    critic2_model.optimizer.apply_gradients(zip(critic2_gradient, critic2_model.trainable_variables))\n",
        "\n",
        "@tf.function    \n",
        "def update_actor(states):\n",
        "    entropy_scale = tf.convert_to_tensor(alpha)\n",
        "    with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
        "        tape.watch(actor_model.trainable_variables)\n",
        "        _, new_policy_actions, log_probs = actor_model(states)\n",
        "        q1_n = critic_model([states, new_policy_actions])\n",
        "        q2_n = critic2_model([states, new_policy_actions])                    \n",
        "        critic_v = tf.reduce_min([q1_n,q2_n],axis=0)      \n",
        "        actor_loss = critic_v - entropy_scale*log_probs \n",
        "        actor_loss = -tf.reduce_mean(actor_loss)\n",
        "    actor_gradient = tape.gradient(actor_loss, actor_model.trainable_variables)\n",
        "    actor_model.optimizer.apply_gradients(zip(actor_gradient, actor_model.trainable_variables))\n",
        "\n",
        "@tf.function\n",
        "def update_entropy(states):\n",
        "    _, _, log_probs= actor_model(states)\n",
        "    with tf.GradientTape() as tape:\n",
        "        alpha_loss = tf.reduce_mean(- alpha*tf.stop_gradient(log_probs + target_entropy))\n",
        "    alpha_grad = tape.gradient(alpha_loss, [log_alpha])\n",
        "    alpha_optimizer.apply_gradients(zip(alpha_grad, [log_alpha]))\n",
        "\n",
        "\n",
        "def train(total_iterations=total_iterations):\n",
        "    i = 0\n",
        "    mean_speed = 0\n",
        "    ep = 0\n",
        "    avg_reward = 0\n",
        "    while i<total_iterations:\n",
        "\n",
        "        prev_state = racer.reset()\n",
        "        episodic_reward = 0\n",
        "        mean_speed += prev_state[4]\n",
        "        done = False\n",
        "\n",
        "        while not(done):\n",
        "            i = i+1\n",
        "\n",
        "            tf_prev_state = tf.expand_dims(tf.convert_to_tensor(prev_state), 0)\n",
        "            _, action, _= actor_model(tf_prev_state)\n",
        "            state, reward, done = step(action)\n",
        "            \n",
        "            #we distinguish between termination with failure (state = None) and succesfull termination on track completion\n",
        "            #succesfull termination is stored as a normal tuple\n",
        "            fail = done and len(state)<5 \n",
        "            buffer.record((prev_state, action, reward, fail, state))\n",
        "            if not(done):\n",
        "                mean_speed += state[4]\n",
        "        \n",
        "            episodic_reward += reward\n",
        "\n",
        "            if buffer.buffer_counter>batch_size:\n",
        "                states,actions,rewards,dones,newstates = buffer.sample_batch()\n",
        "                states = tf.stack(tf.convert_to_tensor(states, dtype=tf.float32))\n",
        "                actions = tf.stack(tf.convert_to_tensor(actions, dtype=tf.float32))\n",
        "                rewards = tf.stack(tf.convert_to_tensor(rewards, dtype=tf.float32))\n",
        "                dones = tf.stack(tf.convert_to_tensor(dones, dtype=tf.float32))\n",
        "                newstates = tf.stack(tf.convert_to_tensor(newstates, dtype=tf.float32))\n",
        "                \n",
        "                update_critics(states, actions, rewards, dones, newstates)\n",
        "                update_actor(states)\n",
        "                update_entropy(states)\n",
        "                update_target(target_critic.variables, critic_model.variables, tau)\n",
        "                update_target(target_critic2.variables, critic2_model.variables, tau)\n",
        "                \n",
        "            prev_state = state\n",
        "            \n",
        "            if i%100 == 0:\n",
        "                avg_reward_list.append(avg_reward)\n",
        "\n",
        "        ep_reward_list.append(episodic_reward)\n",
        "\n",
        "        # Mean of last 40 episodes\n",
        "        avg_reward = np.mean(ep_reward_list[-40:])\n",
        "        print(\"Episode {}: Iterations {}, Avg. Reward = {}, Last reward = {}. Avg. speed = {}\".format(ep, i, avg_reward,episodic_reward,mean_speed/i))\n",
        "        print(\"\\n\")\n",
        "        \n",
        "        if ep>0 and ep%40 == 0:\n",
        "            print(\"## Evaluating policy ##\")\n",
        "            tracks.metrics_run(actor_model, 10)\n",
        "        ep += 1\n",
        "\n",
        "    if total_iterations > 0:\n",
        "        if save_weights:\n",
        "            critic_model.save(weights_file_critic)\n",
        "            critic2_model.save(weights_file_critic2)\n",
        "            actor_model.save(weights_file_actor) \n",
        "        # Plotting Episodes versus Avg. Rewards\n",
        "        plt.plot(avg_reward_list)\n",
        "        plt.xlabel(\"Training steps x100\")\n",
        "        plt.ylabel(\"Avg. Episodic Reward\")\n",
        "        plt.ylim(-3.5,7)\n",
        "        plt.show(block=False)\n",
        "        plt.pause(0.001)\n",
        "        print(\"### SAC Training ended ###\")\n",
        "        print(\"Trained over {} steps\".format(i))\n",
        "\n",
        "if is_training:\n",
        "    start_t = datetime.now()\n",
        "    train(total_iterations=50_000)\n",
        "    end_t = datetime.now()\n",
        "    print(\"Time elapsed: {}\".format(end_t-start_t))"
      ],
      "metadata": {
        "id": "83AtjBPoIYCM"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To compete, we will be use the actor model\n",
        "sac_model = actor_model"
      ],
      "metadata": {
        "id": "r2KcAwi0Ir0a"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compare the results by letting the models compete!\n",
        "In MicroRacer, given a sequence of Actor models, it’s pretty easy to letting them compete to visualize (in an Animation) which is better. This can be done by the function newrun from the tracks.py module. That function takes as input a list of Actor models and returns an animation of the models competing.\n",
        "\n",
        "Note that, in Google Colab, due to the modifications we did at the beginning, the animation won’t be visualized on the screen, it will be saved in a .gif format."
      ],
      "metadata": {
        "id": "V4IW19FAIo9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tracks.newrun([ddpg_model, ddpg2_model, ppo_model, sac_model])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "2QzjNnvoIyeI",
        "outputId": "f95abec4-5ffd-482f-9b24-376e31ad9499"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initial speed =  0.30388312554002955\n",
            "initial speed =  0.30388312554002955\n",
            "initial speed =  0.30388312554002955\n",
            "initial speed =  0.30388312554002955\n",
            "crossing border\n",
            "crossing border\n",
            "completed\n",
            "completed\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x864 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}