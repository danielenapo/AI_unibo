{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2mmcVtW1NUo"
      },
      "source": [
        "# RNN and Transformers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVw8qZ4H1KsP"
      },
      "source": [
        "In this lab lesson we will see how and when to use Recurrent Neural Networks and how to exploits pre-trained Transformers model like Bert.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f4UeT2u2vgq"
      },
      "source": [
        "## Task description\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAUzFjP_3YAa"
      },
      "source": [
        "In this exercise we will try to classify subjectivity of text in sentences.\n",
        "\n",
        "We will use a collection of 103 Italian newspaper's articles labeled as Objective or Subjective. Each article is divided in sentences, which are consequently classified as either Subjective or Objective.\n",
        "\n",
        "You can find the data along with a more detailed description [here](https://github.com/francescoantici/SubjectivITA).\n",
        "\n",
        "We will be trying to create a model which is able to predict if a sentence contains subjectivity or it is fully objective.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hJ8KsB215Kp"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9QypPJoE1ylP"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.utils.class_weight import compute_class_weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTi3RT8Z3uON"
      },
      "source": [
        "## Data loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtmNGBY64aKX"
      },
      "source": [
        "Please download the train, val and test files from the [repository](https://github.com/francescoantici/SubjectivITA/tree/main/datasets/sentences).\n",
        "\n",
        "After having uploaded the three files to the notebook, use this utility function to load the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vvByVSDP4ln7"
      },
      "outputs": [],
      "source": [
        "def get_data_split(split):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "    - split: the split of the data you want to load.\n",
        "  Returns:\n",
        "    - X, y data, where X is the array containing the sentences and y is the labels vector.\n",
        "\n",
        "  \"\"\"\n",
        "  df = pd.read_csv(f\"sentences{split.capitalize()}.csv\")\n",
        "  return df['FRASE'].values, df['TAG_FRASE'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qdNzDM2W5PkG"
      },
      "outputs": [],
      "source": [
        "sentences_train, labels_train = get_data_split(split = 'train')\n",
        "sentences_val, labels_val = get_data_split(split = 'val')\n",
        "sentences_test, labels_test = get_data_split(split = 'test')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upAynpZE5grI"
      },
      "source": [
        "### Data Inspection"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_train"
      ],
      "metadata": {
        "id": "QnbqdKMR5S2R",
        "outputId": "a705d0e4-9c89-4dca-cd31-aead63782904",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Prova estrema su TikTok:',\n",
              "       'bambina di 10 anni in coma a Palermo, dichiarata la morte cerebrale.',\n",
              "       'Inchiesta per istigazione al suicidio.', ...,\n",
              "       'è quanto ha detto Guido Bertolaso, nuovo consulente della Lombardia per la campagna vaccinale regionale, nel corso di una conferenza stampa con il presidente Attilio Fontana e la vicepresidente Letizia Moratti.',\n",
              "       'Non voglio soldi, faccio il volontario e mi sono abbassato lo stipendio: da un euro zero,',\n",
              "       'ha aggiunto.'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_train"
      ],
      "metadata": {
        "id": "ud4boUYN5VKl",
        "outputId": "0c33112c-c20f-40a0-9a3f-1e4730e05224",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['OGG', 'OGG', 'OGG', ..., 'OGG', 'SOG', 'OGG'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7-hGV0u5qux"
      },
      "source": [
        "## RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywLGSfth7wrb"
      },
      "source": [
        "Recurrent neural networks (RNN) are a class of neural networks that is powerful for\n",
        "modeling sequence data such as time series or natural language.\n",
        "\n",
        "Schematically, a RNN layer uses a `for` loop to iterate over the timesteps of a\n",
        "sequence, while maintaining an internal state that encodes information about the\n",
        "timesteps it has seen so far.\n",
        "\n",
        "The Keras RNN API is designed with a focus on:\n",
        "\n",
        "- **Ease of use**: the built-in `keras.layers.RNN`, `keras.layers.LSTM`,\n",
        "`keras.layers.GRU` layers enable you to quickly build recurrent models without\n",
        "having to make difficult configuration choices.\n",
        "\n",
        "- **Ease of customization**: You can also define your own RNN cell layer (the inner\n",
        "part of the `for` loop) with custom behavior, and use it with the generic\n",
        "`keras.layers.RNN` layer (the `for` loop itself). This allows you to quickly\n",
        "prototype different research ideas in a flexible way with minimal code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cXxjtEM765h"
      },
      "source": [
        "There are three built-in RNN layers in Keras:\n",
        "\n",
        "1. `keras.layers.SimpleRNN`, a fully-connected RNN where the output from previous\n",
        "timestep is to be fed to next timestep.\n",
        "\n",
        "2. `keras.layers.GRU`, first proposed in\n",
        "[Cho et al., 2014](https://arxiv.org/abs/1406.1078).\n",
        "\n",
        "3. `keras.layers.LSTM`, first proposed in\n",
        "[Hochreiter & Schmidhuber, 1997](https://www.bioinf.jku.at/publications/older/2604.pdf)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9Xg_LD_79uT"
      },
      "source": [
        "### Data pre-processsing\n",
        "\n",
        "We will use a tokenizer [function](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer) provided by Keras to map each token to an integer, so that the model is able to interpreter it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dL-CjtIr782R"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "\n",
        "lbl_to_idx_dict = {\"OGG\":0, \"SOG\":1}\n",
        "\n",
        "label_to_idx_f = np.vectorize(lbl_to_idx_dict.get)\n",
        "\n",
        "vocabulary_dim = 10000\n",
        "\n",
        "def get_tokenizer(x_train): #all the words are encoded in a dictionary as numbers. kearas has a tokenizer method which does it for us.\n",
        "  tokenizer = Tokenizer(num_words = vocabulary_dim)\n",
        "  tokenizer.fit_on_texts(x_train)\n",
        "  return tokenizer\n",
        "\n",
        "tokenizer = get_tokenizer(sentences_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "id": "MDqWEtx96LVB",
        "outputId": "16460364-0ab0-40df-945c-9bb77638f638",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'di': 1,\n",
              " 'e': 2,\n",
              " 'il': 3,\n",
              " 'che': 4,\n",
              " 'la': 5,\n",
              " 'a': 6,\n",
              " 'in': 7,\n",
              " 'per': 8,\n",
              " 'è': 9,\n",
              " 'un': 10,\n",
              " 'i': 11,\n",
              " 'del': 12,\n",
              " 'della': 13,\n",
              " 'non': 14,\n",
              " 'ha': 15,\n",
              " 'le': 16,\n",
              " 'con': 17,\n",
              " 'si': 18,\n",
              " 'una': 19,\n",
              " 'sono': 20,\n",
              " 'da': 21,\n",
              " 'al': 22,\n",
              " 'più': 23,\n",
              " 'dei': 24,\n",
              " 'alla': 25,\n",
              " 'anche': 26,\n",
              " 'nel': 27,\n",
              " 'ma': 28,\n",
              " 'delle': 29,\n",
              " 'hanno': 30,\n",
              " 'gli': 31,\n",
              " 'come': 32,\n",
              " 'lo': 33,\n",
              " 'sul': 34,\n",
              " 'nella': 35,\n",
              " 'su': 36,\n",
              " 'stato': 37,\n",
              " 'se': 38,\n",
              " 'anni': 39,\n",
              " 'due': 40,\n",
              " 'stati': 41,\n",
              " 'dal': 42,\n",
              " 'dopo': 43,\n",
              " 'fatto': 44,\n",
              " 'loro': 45,\n",
              " 'governo': 46,\n",
              " 'tra': 47,\n",
              " 'prima': 48,\n",
              " 'dalla': 49,\n",
              " 'presidente': 50,\n",
              " 'alle': 51,\n",
              " 'ai': 52,\n",
              " 'era': 53,\n",
              " 'essere': 54,\n",
              " 'parte': 55,\n",
              " 'degli': 56,\n",
              " 'nei': 57,\n",
              " 'poi': 58,\n",
              " 'o': 59,\n",
              " 'tutti': 60,\n",
              " 'giorni': 61,\n",
              " 'questo': 62,\n",
              " 'cui': 63,\n",
              " 'solo': 64,\n",
              " 'ancora': 65,\n",
              " 'aveva': 66,\n",
              " 'sulla': 67,\n",
              " 'ci': 68,\n",
              " 'via': 69,\n",
              " 'nelle': 70,\n",
              " 'questa': 71,\n",
              " 'casa': 72,\n",
              " 'persone': 73,\n",
              " 'altri': 74,\n",
              " 'giorno': 75,\n",
              " 'quando': 76,\n",
              " 'nuovo': 77,\n",
              " 'suo': 78,\n",
              " 'sempre': 79,\n",
              " 'trump': 80,\n",
              " 'perché': 81,\n",
              " 'ad': 82,\n",
              " 'oggi': 83,\n",
              " 'detto': 84,\n",
              " 'polizia': 85,\n",
              " 'fare': 86,\n",
              " 'proprio': 87,\n",
              " 'quanto': 88,\n",
              " 'già': 89,\n",
              " 'ed': 90,\n",
              " 'fa': 91,\n",
              " 'milioni': 92,\n",
              " 'lavoro': 93,\n",
              " 'mentre': 94,\n",
              " 'abbiamo': 95,\n",
              " 'questi': 96,\n",
              " 'sia': 97,\n",
              " 'italia': 98,\n",
              " 'stata': 99,\n",
              " 'quello': 100,\n",
              " 'noi': 101,\n",
              " 'così': 102,\n",
              " 'dove': 103,\n",
              " 'uno': 104,\n",
              " 'quella': 105,\n",
              " 'secondo': 106,\n",
              " 'contro': 107,\n",
              " 'ne': 108,\n",
              " 'sarà': 109,\n",
              " 'aver': 110,\n",
              " 'tutto': 111,\n",
              " 'conte': 112,\n",
              " 'renzi': 113,\n",
              " 'dai': 114,\n",
              " 'paese': 115,\n",
              " 'punto': 116,\n",
              " 'chi': 117,\n",
              " 'donne': 118,\n",
              " '–': 119,\n",
              " 'vaccini': 120,\n",
              " 'alcuni': 121,\n",
              " 'sui': 122,\n",
              " 'ieri': 123,\n",
              " 'sua': 124,\n",
              " 'dalle': 125,\n",
              " 'm5s': 126,\n",
              " 'bambina': 127,\n",
              " 'agli': 128,\n",
              " 'crisi': 129,\n",
              " 'fine': 130,\n",
              " 'tre': 131,\n",
              " 'molto': 132,\n",
              " 'regioni': 133,\n",
              " 'negli': 134,\n",
              " 'ora': 135,\n",
              " 'invece': 136,\n",
              " 'tempo': 137,\n",
              " 'maggioranza': 138,\n",
              " 'ore': 139,\n",
              " 'situazione': 140,\n",
              " 'nuovi': 141,\n",
              " 'altre': 142,\n",
              " 'mi': 143,\n",
              " 'caso': 144,\n",
              " 'mesi': 145,\n",
              " 'viva': 146,\n",
              " 'può': 147,\n",
              " 'draghi': 148,\n",
              " 'carabinieri': 149,\n",
              " 'senza': 150,\n",
              " 'quale': 151,\n",
              " 'rispetto': 152,\n",
              " 'lui': 153,\n",
              " 'c’è': 154,\n",
              " 'ogni': 155,\n",
              " 'politica': 156,\n",
              " 'però': 157,\n",
              " 'locale': 158,\n",
              " 'vita': 159,\n",
              " 'avrebbe': 160,\n",
              " 'programma': 161,\n",
              " 'tavolo': 162,\n",
              " 'stesso': 163,\n",
              " '2': 164,\n",
              " 'campagna': 165,\n",
              " 'tutte': 166,\n",
              " 'commissione': 167,\n",
              " 'giustizia': 168,\n",
              " 'dello': 169,\n",
              " 'matteo': 170,\n",
              " 'modo': 171,\n",
              " 'gennaio': 172,\n",
              " 'pd': 173,\n",
              " 'durante': 174,\n",
              " 'viene': 175,\n",
              " 'momento': 176,\n",
              " 'subito': 177,\n",
              " 'nuova': 178,\n",
              " 'base': 179,\n",
              " 'ministro': 180,\n",
              " 'primo': 181,\n",
              " 'de': 182,\n",
              " 'quel': 183,\n",
              " 'oltre': 184,\n",
              " 'dicembre': 185,\n",
              " 'queste': 186,\n",
              " 'dice': 187,\n",
              " 'fino': 188,\n",
              " 'banchi': 189,\n",
              " 'san': 190,\n",
              " 'fra': 191,\n",
              " 'siamo': 192,\n",
              " 'possibile': 193,\n",
              " 'settimana': 194,\n",
              " 'quindi': 195,\n",
              " 'potrebbe': 196,\n",
              " 'dunque': 197,\n",
              " 'dovrebbe': 198,\n",
              " 'uniti': 199,\n",
              " 'dato': 200,\n",
              " 'mezzo': 201,\n",
              " 'regione': 202,\n",
              " 'bonafede': 203,\n",
              " 'state': 204,\n",
              " 'controllo': 205,\n",
              " 'avevano': 206,\n",
              " 'biden': 207,\n",
              " 'sta': 208,\n",
              " 'vaccino': 209,\n",
              " 'stampa': 210,\n",
              " 'cosa': 211,\n",
              " \"c'è\": 212,\n",
              " 'insomma': 213,\n",
              " 'cittadini': 214,\n",
              " 'ciò': 215,\n",
              " 'covid': 216,\n",
              " 'soprattutto': 217,\n",
              " 'messo': 218,\n",
              " 'quattro': 219,\n",
              " 'sulle': 220,\n",
              " 'brindisi': 221,\n",
              " 'sarebbe': 222,\n",
              " 'circa': 223,\n",
              " 'pandemia': 224,\n",
              " 'chiesto': 225,\n",
              " 'regime': 226,\n",
              " 'europea': 227,\n",
              " 'sue': 228,\n",
              " 'allo': 229,\n",
              " 'erano': 230,\n",
              " 'suoi': 231,\n",
              " 'social': 232,\n",
              " 'campo': 233,\n",
              " 'mercato': 234,\n",
              " 'continua': 235,\n",
              " 'mai': 236,\n",
              " 'capo': 237,\n",
              " 'sicurezza': 238,\n",
              " 'deciso': 239,\n",
              " 'nostro': 240,\n",
              " 'salute': 241,\n",
              " '000': 242,\n",
              " 'quelli': 243,\n",
              " 'conferenza': 244,\n",
              " '4': 245,\n",
              " 'numero': 246,\n",
              " 'cina': 247,\n",
              " 'arriva': 248,\n",
              " 'infatti': 249,\n",
              " 'paesi': 250,\n",
              " 'tempi': 251,\n",
              " 'mario': 252,\n",
              " 'lavori': 253,\n",
              " 'no': 254,\n",
              " 'nessuno': 255,\n",
              " 'roma': 256,\n",
              " 'prescrizione': 257,\n",
              " 'centro': 258,\n",
              " 'ormai': 259,\n",
              " 'camera': 260,\n",
              " 'ho': 261,\n",
              " 'robinhood': 262,\n",
              " '30': 263,\n",
              " 'mila': 264,\n",
              " 'misure': 265,\n",
              " 'reddito': 266,\n",
              " 'domenica': 267,\n",
              " '9': 268,\n",
              " 'agenti': 269,\n",
              " 'altro': 270,\n",
              " 'pfizer': 271,\n",
              " 'venerdì': 272,\n",
              " 'coronavirus': 273,\n",
              " 'fronte': 274,\n",
              " 'sembra': 275,\n",
              " 'morti': 276,\n",
              " 'nulla': 277,\n",
              " 'ex': 278,\n",
              " 'spiega': 279,\n",
              " 'saranno': 280,\n",
              " 'dati': 281,\n",
              " 'processo': 282,\n",
              " 'entro': 283,\n",
              " 'bianca': 284,\n",
              " 'né': 285,\n",
              " 'sera': 286,\n",
              " 'propria': 287,\n",
              " 'dire': 288,\n",
              " 'sotto': 289,\n",
              " 'volte': 290,\n",
              " 'corso': 291,\n",
              " 'tribunale': 292,\n",
              " 'grandi': 293,\n",
              " 'mondo': 294,\n",
              " 'fico': 295,\n",
              " 'molti': 296,\n",
              " 'diverse': 297,\n",
              " '3': 298,\n",
              " 'tutta': 299,\n",
              " 'possibilità': 300,\n",
              " 'posto': 301,\n",
              " 'vedere': 302,\n",
              " 'partito': 303,\n",
              " 'mia': 304,\n",
              " 'febbraio': 305,\n",
              " 'video': 306,\n",
              " 'confronti': 307,\n",
              " 'navalny': 308,\n",
              " 'morte': 309,\n",
              " 'sanitario': 310,\n",
              " 'arrivato': 311,\n",
              " 'insieme': 312,\n",
              " 'famiglia': 313,\n",
              " 'seguito': 314,\n",
              " 'terra': 315,\n",
              " 'piano': 316,\n",
              " 'settimane': 317,\n",
              " 'far': 318,\n",
              " 'mettere': 319,\n",
              " 'dosi': 320,\n",
              " 'fase': 321,\n",
              " 'quali': 322,\n",
              " 'test': 323,\n",
              " 'primi': 324,\n",
              " 'uomini': 325,\n",
              " 'donald': 326,\n",
              " 'all’interno': 327,\n",
              " 'ultimi': 328,\n",
              " 'serie': 329,\n",
              " 'avere': 330,\n",
              " 'comunque': 331,\n",
              " 'intanto': 332,\n",
              " 'e’': 333,\n",
              " 'deve': 334,\n",
              " 'condizioni': 335,\n",
              " 'parole': 336,\n",
              " 'nonostante': 337,\n",
              " 'locali': 338,\n",
              " 'visto': 339,\n",
              " 'piccoli': 340,\n",
              " 'nome': 341,\n",
              " 'leader': 342,\n",
              " 'servizio': 343,\n",
              " 'importante': 344,\n",
              " 'unità': 345,\n",
              " 'lì': 346,\n",
              " 'dollari': 347,\n",
              " 'facebook': 348,\n",
              " 'unito': 349,\n",
              " 'dipartimento': 350,\n",
              " 'possono': 351,\n",
              " 'lavoratori': 352,\n",
              " 'fuoco': 353,\n",
              " 'testa': 354,\n",
              " 'mattarella': 355,\n",
              " 'lombardia': 356,\n",
              " 'avanti': 357,\n",
              " 'provincia': 358,\n",
              " 'dovuto': 359,\n",
              " 'portavoce': 360,\n",
              " 'davanti': 361,\n",
              " 'nostre': 362,\n",
              " 'anticovid': 363,\n",
              " 'decisione': 364,\n",
              " 'riunione': 365,\n",
              " 'affari': 366,\n",
              " 'roberto': 367,\n",
              " 'rischio': 368,\n",
              " 'quota': 369,\n",
              " 'aziende': 370,\n",
              " 'luca': 371,\n",
              " 'mese': 372,\n",
              " 'quasi': 373,\n",
              " 'vaccinare': 374,\n",
              " '2019': 375,\n",
              " 'pubblico': 376,\n",
              " 'norme': 377,\n",
              " 'stanno': 378,\n",
              " 'fuori': 379,\n",
              " 'storia': 380,\n",
              " 'ce': 381,\n",
              " 'studio': 382,\n",
              " 'fosse': 383,\n",
              " 'giugno': 384,\n",
              " 'sabato': 385,\n",
              " 'poco': 386,\n",
              " 'boschi': 387,\n",
              " 'travaglio': 388,\n",
              " 'vuole': 389,\n",
              " '5': 390,\n",
              " 'post': 391,\n",
              " 'segretario': 392,\n",
              " 'trattativa': 393,\n",
              " 'spiegato': 394,\n",
              " 'li': 395,\n",
              " 'alcune': 396,\n",
              " 'euro': 397,\n",
              " 'piattaforma': 398,\n",
              " '—': 399,\n",
              " 'fondi': 400,\n",
              " 'legge': 401,\n",
              " 'rapporto': 402,\n",
              " 'principale': 403,\n",
              " 'inoltre': 404,\n",
              " 'vengono': 405,\n",
              " 'potere': 406,\n",
              " 'qui': 407,\n",
              " 'sistema': 408,\n",
              " 'studi': 409,\n",
              " 'libertà': 410,\n",
              " 'verbale': 411,\n",
              " 'genova': 412,\n",
              " 'ultime': 413,\n",
              " 'sindaco': 414,\n",
              " 'certo': 415,\n",
              " 'carcere': 416,\n",
              " 'orlando': 417,\n",
              " 'donna': 418,\n",
              " '10': 419,\n",
              " 'palermo': 420,\n",
              " 'particolare': 421,\n",
              " 'chiamata': 422,\n",
              " 'procura': 423,\n",
              " 'autorità': 424,\n",
              " 'indagini': 425,\n",
              " 'martedì': 426,\n",
              " 'scritto': 427,\n",
              " 'meno': 428,\n",
              " 'speranza': 429,\n",
              " 'anziani': 430,\n",
              " 'vaccinale': 431,\n",
              " 'cura': 432,\n",
              " 'alto': 433,\n",
              " 'va': 434,\n",
              " 'noto': 435,\n",
              " 'alcun': 436,\n",
              " 'americano': 437,\n",
              " 'nazionale': 438,\n",
              " 'principali': 439,\n",
              " 'familiari': 440,\n",
              " 'volta': 441,\n",
              " 'richiesta': 442,\n",
              " 'astrazeneca': 443,\n",
              " '13': 444,\n",
              " 'morto': 445,\n",
              " 'ministero': 446,\n",
              " 'consiglio': 447,\n",
              " 'prudenza': 448,\n",
              " 'dobbiamo': 449,\n",
              " 'nessuna': 450,\n",
              " 'propri': 451,\n",
              " 'appena': 452,\n",
              " 'marco': 453,\n",
              " 'presenti': 454,\n",
              " 'scorso': 455,\n",
              " 'adesso': 456,\n",
              " 'moglie': 457,\n",
              " 'nomi': 458,\n",
              " 'spesso': 459,\n",
              " 'dietro': 460,\n",
              " 'forte': 461,\n",
              " 'preso': 462,\n",
              " '15': 463,\n",
              " 'gruppo': 464,\n",
              " 'ladri': 465,\n",
              " 'giovani': 466,\n",
              " 'pochi': 467,\n",
              " 'fonti': 468,\n",
              " 'deforestazione': 469,\n",
              " 'produttori': 470,\n",
              " 'pratiche': 471,\n",
              " 'conto': 472,\n",
              " 'varie': 473,\n",
              " 'ritorno': 474,\n",
              " 'gruppi': 475,\n",
              " 'accordo': 476,\n",
              " 'tanto': 477,\n",
              " 'scrive': 478,\n",
              " 'città': 479,\n",
              " 'mio': 480,\n",
              " 'padre': 481,\n",
              " 'presente': 482,\n",
              " 'rochester': 483,\n",
              " 'annunciato': 484,\n",
              " 'zona': 485,\n",
              " 'senato': 486,\n",
              " \"e'\": 487,\n",
              " 'congresso': 488,\n",
              " 'metri': 489,\n",
              " 'pasta': 490,\n",
              " 'lodo': 491,\n",
              " 'prova': 492,\n",
              " 'genitori': 493,\n",
              " 'fermato': 494,\n",
              " 'personale': 495,\n",
              " 'accaduto': 496,\n",
              " 'resistenza': 497,\n",
              " 'forze': 498,\n",
              " 'figlia': 499,\n",
              " 'sanitaria': 500,\n",
              " 'categorie': 501,\n",
              " 'popolazione': 502,\n",
              " 'organizzata': 503,\n",
              " 'chiede': 504,\n",
              " 'problemi': 505,\n",
              " 'vendita': 506,\n",
              " 'sapere': 507,\n",
              " 'incontri': 508,\n",
              " 'capire': 509,\n",
              " 'verso': 510,\n",
              " '2021': 511,\n",
              " '22': 512,\n",
              " 'dichiarazioni': 513,\n",
              " 'responsabilità': 514,\n",
              " 'anzi': 515,\n",
              " 'papa': 516,\n",
              " 'stessa': 517,\n",
              " 'bene': 518,\n",
              " 'tratta': 519,\n",
              " 'allora': 520,\n",
              " 'bambini': 521,\n",
              " 'confronto': 522,\n",
              " 'ministri': 523,\n",
              " 'ben': 524,\n",
              " 'spostamenti': 525,\n",
              " 'posizione': 526,\n",
              " 'aula': 527,\n",
              " 'penale': 528,\n",
              " '7': 529,\n",
              " 'michele': 530,\n",
              " 'niente': 531,\n",
              " 'molte': 532,\n",
              " 'civile': 533,\n",
              " 'porta': 534,\n",
              " 'alfonso': 535,\n",
              " 'pensare': 536,\n",
              " 'futuro': 537,\n",
              " 'condizione': 538,\n",
              " 'saudita': 539,\n",
              " 'io': 540,\n",
              " 'vigilanza': 541,\n",
              " \"l'ex\": 542,\n",
              " 'forza': 543,\n",
              " 'guardia': 544,\n",
              " 'qualche': 545,\n",
              " 'rotelle': 546,\n",
              " 'attesa': 547,\n",
              " 'purtroppo': 548,\n",
              " 'ragazzi': 549,\n",
              " 'prendere': 550,\n",
              " 'miei': 551,\n",
              " 'riusciti': 552,\n",
              " 'coniugi': 553,\n",
              " 'napoli': 554,\n",
              " 'centrale': 555,\n",
              " 'prime': 556,\n",
              " 'portato': 557,\n",
              " 'salire': 558,\n",
              " 'centinaia': 559,\n",
              " '24': 560,\n",
              " 'causa': 561,\n",
              " 'regno': 562,\n",
              " 'afferma': 563,\n",
              " 'risorse': 564,\n",
              " 'rendere': 565,\n",
              " 'grande': 566,\n",
              " 'universale': 567,\n",
              " 'necessità': 568,\n",
              " 'reale': 569,\n",
              " 'totale': 570,\n",
              " 'proposta': 571,\n",
              " 'scelta': 572,\n",
              " 'opportunità': 573,\n",
              " 'cinque': 574,\n",
              " 'possiamo': 575,\n",
              " 'quirinale': 576,\n",
              " 'iv': 577,\n",
              " 'giornata': 578,\n",
              " 'chiudere': 579,\n",
              " 'posizioni': 580,\n",
              " 'lasciare': 581,\n",
              " 'renziani': 582,\n",
              " 'bassetti': 583,\n",
              " 'attualmente': 584,\n",
              " 'guido': 585,\n",
              " 'titolare': 586,\n",
              " 'sociale': 587,\n",
              " 'strada': 588,\n",
              " 'presenza': 589,\n",
              " 'continuano': 590,\n",
              " 'alta': 591,\n",
              " 'pomeriggio': 592,\n",
              " 'marzo': 593,\n",
              " 'putin': 594,\n",
              " 'russia': 595,\n",
              " 'arrestate': 596,\n",
              " 'fede': 597,\n",
              " 'vero': 598,\n",
              " 'verità': 599,\n",
              " 'politiche': 600,\n",
              " 'bihac': 601,\n",
              " 'craxi': 602,\n",
              " 'zingaretti': 603,\n",
              " 'lunger': 604,\n",
              " 'qanon': 605,\n",
              " 'angelo': 606,\n",
              " 'meloni': 607,\n",
              " 'paisiello': 608,\n",
              " 'pelazza': 609,\n",
              " 'tiktok': 610,\n",
              " 'dichiarato': 611,\n",
              " 'cuore': 612,\n",
              " 'grazie': 613,\n",
              " 'magistratura': 614,\n",
              " 'squadra': 615,\n",
              " 'amici': 616,\n",
              " 'nostra': 617,\n",
              " 'priorità': 618,\n",
              " 'piccola': 619,\n",
              " 'prevede': 620,\n",
              " 'nello': 621,\n",
              " 'vari': 622,\n",
              " 'quadro': 623,\n",
              " 'dinamica': 624,\n",
              " 'meccanismo': 625,\n",
              " 'mercoledì': 626,\n",
              " 'comunicazione': 627,\n",
              " '17': 628,\n",
              " 'arcuri': 629,\n",
              " 'ritardo': 630,\n",
              " 'prossime': 631,\n",
              " 'sorta': 632,\n",
              " 'regionali': 633,\n",
              " '20': 634,\n",
              " 'pazienti': 635,\n",
              " 'fragili': 636,\n",
              " 'atto': 637,\n",
              " 'vaccinazione': 638,\n",
              " 'maria': 639,\n",
              " 'notizia': 640,\n",
              " 'sei': 641,\n",
              " 'sugli': 642,\n",
              " 'economica': 643,\n",
              " 'dell’amministrazione': 644,\n",
              " 'maggior': 645,\n",
              " 'almeno': 646,\n",
              " 'politici': 647,\n",
              " 'popolo': 648,\n",
              " 'sviluppo': 649,\n",
              " '28': 650,\n",
              " 'istituzioni': 651,\n",
              " 'aggiunto': 652,\n",
              " 'disponibili': 653,\n",
              " 'produzione': 654,\n",
              " '29': 655,\n",
              " '80': 656,\n",
              " 'prevista': 657,\n",
              " 'washington': 658,\n",
              " 'messi': 659,\n",
              " 'italiana': 660,\n",
              " 'celebrare': 661,\n",
              " 'custodia': 662,\n",
              " 'lontano': 663,\n",
              " \"l'ipotesi\": 664,\n",
              " 'sì': 665,\n",
              " 'mascherina': 666,\n",
              " 'probabilmente': 667,\n",
              " \"d'italia\": 668,\n",
              " 'difficile': 669,\n",
              " 'strage': 670,\n",
              " 'cassazione': 671,\n",
              " 'avvocati': 672,\n",
              " 'vittime': 673,\n",
              " 'chiediamo': 674,\n",
              " 'periodo': 675,\n",
              " 'verrà': 676,\n",
              " 'gravi': 677,\n",
              " 'qualcuno': 678,\n",
              " 'figli': 679,\n",
              " 'maniera': 680,\n",
              " 'economico': 681,\n",
              " 'lei': 682,\n",
              " 'resta': 683,\n",
              " 'guida': 684,\n",
              " 'faremo': 685,\n",
              " 'cronoprogramma': 686,\n",
              " 'bin': 687,\n",
              " 'laden': 688,\n",
              " 'lucia': 689,\n",
              " 'me': 690,\n",
              " 'accusato': 691,\n",
              " 'vede': 692,\n",
              " 'stiamo': 693,\n",
              " 'alleati': 694,\n",
              " 'giuseppe': 695,\n",
              " 'politico': 696,\n",
              " 'mandato': 697,\n",
              " 'arrivati': 698,\n",
              " 'po’': 699,\n",
              " 'avuto': 700,\n",
              " 'coppia': 701,\n",
              " 'successo': 702,\n",
              " 'residenti': 703,\n",
              " 'vive': 704,\n",
              " 'buon': 705,\n",
              " 'presso': 706,\n",
              " 'strutture': 707,\n",
              " 'street': 708,\n",
              " 'scorsi': 709,\n",
              " 'calo': 710,\n",
              " 'considerato': 711,\n",
              " 'migliaia': 712,\n",
              " 'società': 713,\n",
              " 'riferimento': 714,\n",
              " 'tasso': 715,\n",
              " 'divieto': 716,\n",
              " 'soluzione': 717,\n",
              " '1': 718,\n",
              " 'torre': 719,\n",
              " 'ugarte': 720,\n",
              " 'luogo': 721,\n",
              " 'cambiamenti': 722,\n",
              " 'cambiare': 723,\n",
              " 'aumentare': 724,\n",
              " 'sostenibili': 725,\n",
              " 'agricoltori': 726,\n",
              " 'trovano': 727,\n",
              " 'genere': 728,\n",
              " 'migliore': 729,\n",
              " 'aumento': 730,\n",
              " 'posti': 731,\n",
              " 'contagio': 732,\n",
              " 'garantire': 733,\n",
              " 'diritto': 734,\n",
              " 'denaro': 735,\n",
              " 'rientrare': 736,\n",
              " 'dagli': 737,\n",
              " 'guerra': 738,\n",
              " 'meglio': 739,\n",
              " 'tratto': 740,\n",
              " 'ti': 741,\n",
              " 'danno': 742,\n",
              " 'pari': 743,\n",
              " 'atti': 744,\n",
              " 'lasciato': 745,\n",
              " 'sergio': 746,\n",
              " 'voluto': 747,\n",
              " 'aggiunge': 748,\n",
              " 'riprese': 749,\n",
              " 'presto': 750,\n",
              " 'perso': 751,\n",
              " 'palazzo': 752,\n",
              " 'minacce': 753,\n",
              " 'inviato': 754,\n",
              " '660': 755,\n",
              " 'campania': 756,\n",
              " 'bertolaso': 757,\n",
              " 'raccolta': 758,\n",
              " 'occhi': 759,\n",
              " 'cento': 760,\n",
              " 'storico': 761,\n",
              " 'billy': 762,\n",
              " 'novembre': 763,\n",
              " 'vista': 764,\n",
              " 'madre': 765,\n",
              " 'conclude': 766,\n",
              " 'convinto': 767,\n",
              " 'comandante': 768,\n",
              " 'sarno': 769,\n",
              " 'fratelli': 770,\n",
              " 'romano': 771,\n",
              " 'pagine': 772,\n",
              " 'decreto': 773,\n",
              " 'l’amministrazione': 774,\n",
              " 'elettorale': 775,\n",
              " 'fatti': 776,\n",
              " 'seconda': 777,\n",
              " 'responsabile': 778,\n",
              " 'germania': 779,\n",
              " 'servizi': 780,\n",
              " '12': 781,\n",
              " 'dicendo': 782,\n",
              " 'chiesa': 783,\n",
              " 'riforma': 784,\n",
              " 'joe': 785,\n",
              " 'carica': 786,\n",
              " 'psaki': 787,\n",
              " 'sanità': 788,\n",
              " 'americana': 789,\n",
              " 'leu': 790,\n",
              " 'vera': 791,\n",
              " 'pericolo': 792,\n",
              " 'voto': 793,\n",
              " 'blocco': 794,\n",
              " 'licenziamenti': 795,\n",
              " 'femminile': 796,\n",
              " 'raggiungere': 797,\n",
              " 'strategia': 798,\n",
              " 'serray': 799,\n",
              " 'esecutivo': 800,\n",
              " 'consiglieri': 801,\n",
              " 'l’aborto': 802,\n",
              " 'violenza': 803,\n",
              " 'manager': 804,\n",
              " 'manson': 805,\n",
              " 'soncini': 806,\n",
              " 'nessun': 807,\n",
              " 'arrivata': 808,\n",
              " 'medici': 809,\n",
              " 'finora': 810,\n",
              " 'trovava': 811,\n",
              " 'cintura': 812,\n",
              " 'gola': 813,\n",
              " 'sfida': 814,\n",
              " 'ospedale': 815,\n",
              " 'cellulare': 816,\n",
              " 'commentato': 817,\n",
              " 'attorno': 818,\n",
              " 'soccorso': 819,\n",
              " 'contatto': 820,\n",
              " 'domenico': 821,\n",
              " 'parla': 822,\n",
              " 'chiedendo': 823,\n",
              " 'devono': 824,\n",
              " 'vertice': 825,\n",
              " 'francesco': 826,\n",
              " 'boccia': 827,\n",
              " 'accesso': 828,\n",
              " 'sottolineato': 829,\n",
              " 'fondazione': 830,\n",
              " 'rinaldi': 831,\n",
              " 'accusa': 832,\n",
              " 'gestione': 833,\n",
              " 'direttore': 834,\n",
              " 'interessi': 835,\n",
              " 'eseguito': 836,\n",
              " 'gravemente': 837,\n",
              " 'relazioni': 838,\n",
              " 'responsabili': 839,\n",
              " 'john': 840,\n",
              " 'zaia': 841,\n",
              " 'veneto': 842,\n",
              " 'diretta': 843,\n",
              " 'auguro': 844,\n",
              " 'contratto': 845,\n",
              " 'operatori': 846,\n",
              " 'cerca': 847,\n",
              " 'andare': 848,\n",
              " \"l'impegno\": 849,\n",
              " 'strade': 850,\n",
              " 'riesce': 851,\n",
              " 'siano': 852,\n",
              " 'concluso': 853,\n",
              " 'bisogno': 854,\n",
              " 'nota': 855,\n",
              " 'europei': 856,\n",
              " 'ricevuto': 857,\n",
              " '200': 858,\n",
              " 'sanitari': 859,\n",
              " 'risultato': 860,\n",
              " 'condannati': 861,\n",
              " 'stazione': 862,\n",
              " 'omicidio': 863,\n",
              " 'corte': 864,\n",
              " 'pieno': 865,\n",
              " 'messe': 866,\n",
              " 'natale': 867,\n",
              " 'episcopale': 868,\n",
              " 'questione': 869,\n",
              " 'soggetti': 870,\n",
              " 'chiaro': 871,\n",
              " 'bel': 872,\n",
              " 'vescovi': 873,\n",
              " 'italiani': 874,\n",
              " 'interventi': 875,\n",
              " 'dpcm': 876,\n",
              " 'potrà': 877,\n",
              " 'dà': 878,\n",
              " 'giusto': 879,\n",
              " 'positivi': 880,\n",
              " 'tamponi': 881,\n",
              " 'migliori': 882,\n",
              " 'controlli': 883,\n",
              " 'forma': 884,\n",
              " 'distanza': 885,\n",
              " 'assieme': 886,\n",
              " 'case': 887,\n",
              " 'avranno': 888,\n",
              " 'premier': 889,\n",
              " 'vi': 890,\n",
              " 'anno': 891,\n",
              " 'grado': 892,\n",
              " '6': 893,\n",
              " 'lungo': 894,\n",
              " 'quelle': 895,\n",
              " 'piedi': 896,\n",
              " 'soltanto': 897,\n",
              " 'grave': 898,\n",
              " 'emerse': 899,\n",
              " 'casi': 900,\n",
              " 'quotidiano': 901,\n",
              " 'lite': 902,\n",
              " 'deputata': 903,\n",
              " 'saltare': 904,\n",
              " 'contrario': 905,\n",
              " 'movimento': 906,\n",
              " 'stelle': 907,\n",
              " 'salvo': 908,\n",
              " 'grillino': 909,\n",
              " 'prossimo': 910,\n",
              " 'rischia': 911,\n",
              " 'fu': 912,\n",
              " 'davide': 913,\n",
              " 'ter': 914,\n",
              " 'foto': 915,\n",
              " 'anna': 916,\n",
              " 'deputato': 917,\n",
              " 'nostri': 918,\n",
              " 'monti': 919,\n",
              " 'guidato': 920,\n",
              " 'sostenuto': 921,\n",
              " 'repubblica': 922,\n",
              " 'qualcosa': 923,\n",
              " 'corridoi': 924,\n",
              " 'esigenze': 925,\n",
              " 'innovativi': 926,\n",
              " 'potuto': 927,\n",
              " 'monoposto': 928,\n",
              " 'differenza': 929,\n",
              " 'dirigente': 930,\n",
              " 'capua': 931,\n",
              " 'minorenni': 932,\n",
              " 'urla': 933,\n",
              " 'wall': 934,\n",
              " 'investitori': 935,\n",
              " 'acquisti': 936,\n",
              " 'prendendo': 937,\n",
              " 'rivolta': 938,\n",
              " 'miliardi': 939,\n",
              " '25': 940,\n",
              " 'sola': 941,\n",
              " 'stop': 942,\n",
              " 'clienti': 943,\n",
              " 'angeli': 944,\n",
              " 'sec': 945,\n",
              " 'business': 946,\n",
              " 'borsa': 947,\n",
              " 'protesta': 948,\n",
              " 'diversi': 949,\n",
              " 'multa': 950,\n",
              " 'legati': 951,\n",
              " 'clima': 952,\n",
              " 'affrontare': 953,\n",
              " 'legale': 954,\n",
              " 'significa': 955,\n",
              " 'maggiore': 956,\n",
              " 'maggiori': 957,\n",
              " 'capitale': 958,\n",
              " 'discussione': 959,\n",
              " 'problema': 960,\n",
              " '2008': 961,\n",
              " 'libera': 962,\n",
              " 'prossimi': 963,\n",
              " 'restrizioni': 964,\n",
              " 'benessere': 965,\n",
              " 'conseguenze': 966,\n",
              " 'crescono': 967,\n",
              " 'teoria': 968,\n",
              " 'l’economia': 969,\n",
              " 'perdono': 970,\n",
              " 'coloro': 971,\n",
              " 'new': 972,\n",
              " 'usa': 973,\n",
              " 'attraverso': 974,\n",
              " 'felicità': 975,\n",
              " 'fondamentale': 976,\n",
              " '55': 977,\n",
              " 'proprie': 978,\n",
              " 'comune': 979,\n",
              " 'protezione': 980,\n",
              " 'intesa': 981,\n",
              " 'sala': 982,\n",
              " 'apprende': 983,\n",
              " 'nodo': 984,\n",
              " 'mes': 985,\n",
              " 'temi': 986,\n",
              " 'favorevoli': 987,\n",
              " 'tipo': 988,\n",
              " 'trovare': 989,\n",
              " 'affermano': 990,\n",
              " 'scadenza': 991,\n",
              " '18': 992,\n",
              " 'massimo': 993,\n",
              " 'battaglia': 994,\n",
              " 'messaggio': 995,\n",
              " 'minacciato': 996,\n",
              " '499': 997,\n",
              " 'contagi': 998,\n",
              " 'riguarda': 999,\n",
              " 'somministrazione': 1000,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Zzt_qt9rbk-N"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import pad_sequences\n",
        "\n",
        "maxSentenceLen = 20 #taken after analysis -> sentences are almost never longer than 20. we truncate longer sentences with keras methods\n",
        "\n",
        "generate_x = lambda x: pad_sequences(tokenizer.texts_to_sequences(x), maxlen = maxSentenceLen, padding = \"post\")\n",
        "\n",
        "x_train = generate_x(sentences_train)\n",
        "x_test = generate_x(sentences_test)\n",
        "x_val = generate_x(sentences_val)\n",
        "\n",
        "y_train = label_to_idx_f(labels_train)\n",
        "y_test = label_to_idx_f(labels_test)\n",
        "y_val = label_to_idx_f(labels_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "OUmZqKiic6Zh",
        "outputId": "69caaa17-1510-4c17-f1b1-1c0c3d98861b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1399, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "x_train.shape #1399 sentences with 20 words each (0 = empty word to arrive at 20 if it's shorter)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "id": "Sd3HdQzi86yW",
        "outputId": "d15bd6c7-6a63-4657-96d9-22f4be946250",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 492, 1090,   36, ...,    0,    0,    0],\n",
              "       [ 127,    1,  419, ...,    0,    0,    0],\n",
              "       [2715,    8, 1091, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [   5,  165,  431, ..., 1025, 7126, 7127],\n",
              "       [  14, 1379, 2601, ...,    0,    0,    0],\n",
              "       [  15,  652,    0, ...,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIUdd95k8gop"
      },
      "source": [
        "### Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xokrUCPGqfvZ"
      },
      "source": [
        "let's build a rnn baseline based on LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "GGB2xMC18iwW"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "#notice there are no activations\n",
        "def get_rnn_model(input_shape, out_dim, vocabulary_dim):\n",
        "  input = Input(shape=input_shape)\n",
        "\n",
        "  embedding_layer = Embedding(input_dim=vocabulary_dim, output_dim=64)(input) #embeding word tokens into vector space (can also be one-hot encoding)\n",
        "  #layer that has a grasp of contest\n",
        "  lstm_1 = LSTM(128, return_sequences=True, recurrent_dropout = 0.2)(embedding_layer) #use return_sequence, to output for each sequence and not just the last\n",
        "\n",
        "  lstm_2 = LSTM(64, dropout = 0.2)(lstm_1) #don't return sequences\n",
        "\n",
        "  output = Dense(out_dim)(lstm_2)\n",
        "\n",
        "  model = Model(input, output)\n",
        "\n",
        "  model.compile(loss=SparseCategoricalCrossentropy(from_logits=True), optimizer = Adam(1e-3), metrics = ['accuracy'])\n",
        "  \n",
        "  model.summary()\n",
        "  \n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "LTbbDv8KzqKq"
      },
      "outputs": [],
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy', mode = 'max', patience = 5, restore_best_weights = True) #callback stops training automatically when detecting overfitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "rwXMid6T_n5X",
        "outputId": "0dbee669-df4b-4554-8095-d0363b5e1a11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 20)]              0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 20, 64)            640000    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 20, 128)           98816     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 64)                49408     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 788,354\n",
            "Trainable params: 788,354\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = get_rnn_model((20,), 2, vocabulary_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "qtnrwygRcmTt",
        "outputId": "d0dc52b6-2b74-4c11-9135-3d06118df514",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "44/44 [==============================] - 26s 365ms/step - loss: 0.6129 - accuracy: 0.7091 - val_loss: 0.6595 - val_accuracy: 0.6233\n",
            "Epoch 2/10\n",
            "44/44 [==============================] - 14s 313ms/step - loss: 0.4257 - accuracy: 0.8056 - val_loss: 0.6893 - val_accuracy: 0.7442\n",
            "Epoch 3/10\n",
            "44/44 [==============================] - 9s 213ms/step - loss: 0.1056 - accuracy: 0.9593 - val_loss: 0.9056 - val_accuracy: 0.7209\n",
            "Epoch 4/10\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.0591 - accuracy: 0.9836 - val_loss: 1.3830 - val_accuracy: 0.6698\n",
            "Epoch 5/10\n",
            "44/44 [==============================] - 6s 135ms/step - loss: 0.0176 - accuracy: 0.9950 - val_loss: 1.7175 - val_accuracy: 0.6837\n",
            "Epoch 6/10\n",
            "44/44 [==============================] - 4s 93ms/step - loss: 0.0093 - accuracy: 0.9979 - val_loss: 1.5534 - val_accuracy: 0.6605\n",
            "Epoch 7/10\n",
            "44/44 [==============================] - 5s 118ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 1.7907 - val_accuracy: 0.6884\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(x_train, y_train, epochs=10, validation_data = (x_val, y_val), callbacks = [callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SlpWhGHCiYc"
      },
      "source": [
        "### Model evaluation\n",
        "\n",
        "For the model evaluation we will use the [classification report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html) function provided by scikit-learn, which will present a detailed report of the performances of the model evaluated on different metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "zYBXj27zCkkm"
      },
      "outputs": [],
      "source": [
        "toLabels = np.vectorize(lambda e: \"OGG\" if e == 0 else \"SOG\")\n",
        "\n",
        "def evaluate_model(model, x_test, y_test):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "    - model: the model to use to make the prediction.\n",
        "    - x_test: the sentences to label.\n",
        "    - y_test: the actual labels.\n",
        "  Returns:\n",
        "    - The results of the evaluation of the model.\n",
        "\n",
        "  \"\"\"\n",
        "  y_pred = np.argmax(model.predict(x_test), axis = -1)\n",
        "  #classification report gives a confusion matrix if we're doing classification\n",
        "  print(classification_report(toLabels(y_test), y_pred = toLabels(y_pred)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "m5UA2u5ADfgV",
        "outputId": "22de3768-b1e6-4687-843c-869cff9dda91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 1s 16ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         OGG       0.79      0.76      0.78       152\n",
            "         SOG       0.56      0.60      0.58        75\n",
            "\n",
            "    accuracy                           0.71       227\n",
            "   macro avg       0.68      0.68      0.68       227\n",
            "weighted avg       0.72      0.71      0.71       227\n",
            "\n"
          ]
        }
      ],
      "source": [
        "evaluate_model(model, x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbLopRmb-CN0"
      },
      "source": [
        "#### Bidirectional RNNs\n",
        "\n",
        "For sequences other than time series (e.g. text), it is often the case that a RNN model\n",
        "can perform better if it not only processes sequence from start to end, but also\n",
        "backwards. For example, to predict the next word in a sentence, it is often useful to\n",
        "have the context around the word, not only just the words that come before it.\n",
        "\n",
        "Keras provides an easy API for you to build such **bidirectional RNNs**: the\n",
        "`keras.layers.Bidirectional` wrapper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "_NxMWVoU9971"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Bidirectional, TimeDistributed\n",
        "#it's always worth a try to add a bidirectional layer when dealing with sequences, to see if it improves our predictions (might better understand contex)\n",
        "def get_rnn_model_bd(input_shape, out_dim, vocabulary_length):\n",
        "  input = Input(shape=input_shape)\n",
        "\n",
        "  embedding_layer = Embedding(input_dim=vocabulary_length, output_dim=64)(input)\n",
        "  #same as before, but using bidiretional instead of vanilla LSTM\n",
        "  lstm_1 = Bidirectional(LSTM(128, return_sequences=True, recurrent_dropout = 0.2))(embedding_layer) \n",
        "\n",
        "  lstm_2 = Bidirectional(LSTM(64, dropout = 0.2))(lstm_1)\n",
        "\n",
        "  output = Dense(out_dim)(lstm_2)\n",
        "\n",
        "  model = Model(input, output)\n",
        "\n",
        "  model.compile(loss=SparseCategoricalCrossentropy(from_logits=True), optimizer = Adam(1e-3), metrics = ['accuracy'])\n",
        "  \n",
        "  model.summary()\n",
        "  \n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "aB-tTuuKATXW",
        "outputId": "2592cb47-49f0-4675-eecd-bf57574a720f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 20)]              0         \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 20, 64)            640000    \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 20, 256)          197632    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 128)              164352    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,002,242\n",
            "Trainable params: 1,002,242\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_bd = get_rnn_model_bd((20,), 2, vocabulary_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "odtIo3d6jdC2",
        "outputId": "93b74f13-9598-4c76-c53f-68114cd596bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "44/44 [==============================] - 23s 341ms/step - loss: 0.6189 - accuracy: 0.7134 - val_loss: 0.6630 - val_accuracy: 0.6233\n",
            "Epoch 2/10\n",
            "44/44 [==============================] - 10s 222ms/step - loss: 0.4727 - accuracy: 0.7655 - val_loss: 0.8251 - val_accuracy: 0.7442\n",
            "Epoch 3/10\n",
            "44/44 [==============================] - 10s 234ms/step - loss: 0.1547 - accuracy: 0.9414 - val_loss: 0.7473 - val_accuracy: 0.7023\n",
            "Epoch 4/10\n",
            "44/44 [==============================] - 10s 226ms/step - loss: 0.0412 - accuracy: 0.9878 - val_loss: 1.0008 - val_accuracy: 0.6930\n",
            "Epoch 5/10\n",
            "44/44 [==============================] - 10s 219ms/step - loss: 0.0133 - accuracy: 0.9971 - val_loss: 1.8902 - val_accuracy: 0.6977\n",
            "Epoch 6/10\n",
            "44/44 [==============================] - 8s 186ms/step - loss: 0.0173 - accuracy: 0.9936 - val_loss: 1.8653 - val_accuracy: 0.6744\n",
            "Epoch 7/10\n",
            "44/44 [==============================] - 9s 202ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 1.8972 - val_accuracy: 0.6837\n"
          ]
        }
      ],
      "source": [
        "history = model_bd.fit(x_train, y_train, epochs=10, validation_data = (x_val, y_val), callbacks = [callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "CEfvrHfRjgtt",
        "outputId": "da12b9aa-11c0-4a07-bd77-7eb2b6c1e71a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 1s 15ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         OGG       0.80      0.76      0.78       152\n",
            "         SOG       0.56      0.61      0.59        75\n",
            "\n",
            "    accuracy                           0.71       227\n",
            "   macro avg       0.68      0.69      0.68       227\n",
            "weighted avg       0.72      0.71      0.72       227\n",
            "\n"
          ]
        }
      ],
      "source": [
        "evaluate_model(model_bd, x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9e0VvSD52rV"
      },
      "source": [
        "## Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5U_P9h2t59Bw"
      },
      "source": [
        "Transformers are deep neural networks that over the last years achieved state of the art performances in several tasks.\n",
        "\n",
        "Transformers replaces CNNs and RNNs with [self-attention](https://developers.google.com/machine-learning/glossary#self-attention). Self attention allows Transformers to easily transmit information across the input sequences.\n",
        "\n",
        "For the transformer model implementation we will rely on a Python library called `transformers`, which provides an API inteface to several pre-trained models for fine-tuning or transfer-learning purposes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "bVjERW866TJp",
        "outputId": "0add4d7b-872a-43ad-833c-232f1048a659",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m95.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m110.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n"
          ]
        }
      ],
      "source": [
        "!pip3 install transformers \n",
        "from transformers import AutoTokenizer, TFBertModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQfr8j8OtqEy"
      },
      "source": [
        "### Pre-trained model\n",
        "\n",
        "For this task we will use a pre-trained language model called [AlBERTo](github.com/marcopoli/AlBERTo-it). AlBERTo is a BERT model trained for the Italian language. In particular, AlBERTo is focused on the language used in social networks, specifically on Twitter. Due to the language and the type of data present in the dataset AlBERTo is the best fit for this kind of task.\n",
        "\n",
        "You can find the pre-trained model in [huggingface](https://huggingface.co/bert-base-multilingual-cased?text=mi+piace+il+%5BMASK%5D), which is an open repository for pre-trained architectures, available in both pytorch and tensorflow (depending on the developers)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kM0ZfujT6-J2"
      },
      "source": [
        "### Data pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r__5kvn8BPle"
      },
      "source": [
        "Transoformes must recieve input in a standard format, namely divided in `input_ids`, `token_type_ids`, `attention_mask`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHR30lup67iO"
      },
      "outputs": [],
      "source": [
        "def prepare_data_bert(x, y, maxSentenceLen = maxSentenceLen):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "    - x: the sentences to label.\n",
        "    - y: the actual labels.\n",
        "    - maxSentenceLen: The maximum length of the sentences, it is used as a truncation length\n",
        "  Returns:\n",
        "    - A tuple with the input to feed into a transformers model, namely ((input_ids, attention_mask, token_type_ids), categorical_labels).\n",
        "\n",
        "  \"\"\"\n",
        "  pad = tf.keras.preprocessing.sequence.pad_sequences\n",
        "  tokenizer = AutoTokenizer.from_pretrained(\"m-polignano-uniba/bert_uncased_L-12_H-768_A-12_italian_alb3rt0\")\n",
        "  dataFields = {\n",
        "          \"input_ids\": [],\n",
        "          \"token_type_ids\": [],\n",
        "          \"attention_mask\": [],\n",
        "          \"subjectivity\": []\n",
        "      }\n",
        "  lbls = {\n",
        "      'SOG' : 1.0,\n",
        "      'OGG' : 0.0\n",
        "  }\n",
        "  for i in range(len(x)):\n",
        "      data = tokenizer(x[i])\n",
        "      padded = pad([data['input_ids'], data['attention_mask'], data['token_type_ids']], padding = 'post', maxlen = maxSentenceLen)\n",
        "      dataFields['input_ids'].append(padded[0])\n",
        "      dataFields['attention_mask'].append(padded[1])\n",
        "      dataFields['token_type_ids'].append(padded[-1])\n",
        "      dataFields['subjectivity'].append(lbls[y[i]])\n",
        "  \n",
        "  for key in dataFields:\n",
        "      dataFields[key] = np.array(dataFields[key])\n",
        "  #returns 3 inputs (based on attention), 1 output vector\n",
        "  return [dataFields[\"input_ids\"], dataFields[\"token_type_ids\"], dataFields[\"attention_mask\"]], dataFields[\"subjectivity\"] "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8oDhftmAgoj"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "model has to take a list of 3 inputs, a bert layer and a dense output."
      ],
      "metadata": {
        "id": "5kfeYhE1Bh2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_transformers_model(input_shape, out_dim):\n"
      ],
      "metadata": {
        "id": "LpdiTyRmBEIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model= create_transformers_model(_,_)"
      ],
      "metadata": {
        "id": "7mSvnw8MBEFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hlKebtMaBEDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w3QlwMifBEAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2PAQPDBGBD9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YBD-6W_yBD6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xp9JOIBZBD3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WDpkl-8mBD1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eApCI3_IBDye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xbB7ZHcKBDvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xsIrfcisBDp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcz-g_bfAf-K"
      },
      "outputs": [],
      "source": [
        "def create_transformers_model(input_shape, out_dim):\n",
        "\n",
        "    input_ids = Input(shape=input_shape, dtype=tf.int32)\n",
        "    token_type_ids = Input(shape=input_shape, dtype=tf.int32)\n",
        "    attention_mask = Input(shape=input_shape, dtype=tf.int32)\n",
        "\n",
        "    bertModel = TFBertModel.from_pretrained(\"m-polignano-uniba/bert_uncased_L-12_H-768_A-12_italian_alb3rt0\")(input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask)[-1]\n",
        "\n",
        "    out = Dense(out_dim, activation=tf.nn.sigmoid)(tf.keras.layers.Dropout(0.1)(bertModel))\n",
        "\n",
        "    model = Model(inputs=[input_ids, token_type_ids, attention_mask], outputs=out)\n",
        "\n",
        "    model.compile(optimizer = Adam(1e-5), loss = SparseCategoricalCrossentropy(from_logits=True), metrics = ['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hByBS2IRkibb"
      },
      "outputs": [],
      "source": [
        "bert_model = create_transformers_model((20,), 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBFNY98JuNv0"
      },
      "outputs": [],
      "source": [
        "x_train_bert, y_train_bert = prepare_data_bert(sentences_train, labels_train)\n",
        "x_val_bert, y_val_bert = prepare_data_bert(sentences_val, labels_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukHU9hO7k3Ut"
      },
      "outputs": [],
      "source": [
        "history = bert_model.fit(x_train_bert, \n",
        "                         y_train_bert, \n",
        "                         epochs=4, \n",
        "                         validation_data = (x_val_bert, y_val_bert), \n",
        "                         batch_size = 16, \n",
        "                         callbacks = [callback]\n",
        "                         )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prSfUspMDOFR"
      },
      "source": [
        "### Model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VZGxpniDmRc"
      },
      "outputs": [],
      "source": [
        "x_test_bert, y_test_bert = prepare_data_bert(sentences_test, labels_test)\n",
        "\n",
        "evaluate_model(bert_model, x_test_bert, y_test_bert)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "H9e0VvSD52rV"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}