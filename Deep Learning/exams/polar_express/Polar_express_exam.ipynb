{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHeVMRyBYJH6"
      },
      "source": [
        "# intro\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zw_326KLT9dF"
      },
      "source": [
        "The purpose of the project is to learn the mapping from polar coordinates to a a discrete 10x10 grid of cells in the plane, using a neural network. \n",
        "\n",
        "The supervised dataset is given to you in the form of a generator (to be considered as a black box).\n",
        "\n",
        "The model must achieve an accuracy of 95%, and it will be evaluated in a way **inversely proportional to the number of its parameters: the smaller, the better.**\n",
        "\n",
        "**WARNING**: Any solution taking advantage of meta-knowledge about the generator will be automatically rejected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynz-4_4cFmbJ",
        "outputId": "c7bbcd94-7874-4e3e-82e0-42daf1273645"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Reshape, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow import keras\n",
        "#check if gpu is present\n",
        "tf.config.list_physical_devices('GPU')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iA01pkKbUt7Q"
      },
      "source": [
        "Here is the generator. It returns triples of the form ((theta,rho),out) where (theta,rho) are the polar coordinates of a point in the first quadrant of the plane, and out is a 10x10 map with \"1\" in the cell corresponding to the point position, and \"0\" everywhere else.\n",
        "\n",
        "By setting flat=True, the resulting map is flattened into a vector with a single dimension 100. You can use this variant, if you wish. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "DsA1GqAeWAdo"
      },
      "outputs": [],
      "source": [
        "def polar_generator(batchsize,grid=(10,10),noise=.002,flat=False):\n",
        "  while True:\n",
        "    x = np.random.rand(batchsize)\n",
        "    y = np.random.rand(batchsize)\n",
        "    out = np.zeros((batchsize,grid[0],grid[1]))\n",
        "    xc = (x*grid[0]).astype(int)\n",
        "    yc = (y*grid[1]).astype(int)\n",
        "    for b in range(batchsize):\n",
        "      out[b,xc[b],yc[b]] = 1\n",
        "    #compute rho and theta and add some noise\n",
        "    rho = np.sqrt(x**2+y**2) + np.random.normal(scale=noise)\n",
        "    theta = np.arctan(y/np.maximum(x,.00001)) + np.random.normal(scale=noise)\n",
        "    if flat:\n",
        "      out = np.reshape(out,(batchsize,grid[0]*grid[1]))\n",
        "    yield ((theta,rho),out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF-jlaqAWc2o"
      },
      "source": [
        "Let's create an instance of the generator on a grid with dimension 3x4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "Ov3rXaLVHDCT"
      },
      "outputs": [],
      "source": [
        "g1,g2 = 3,4\n",
        "gen = polar_generator(1,grid=(g1,g2),noise=0.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4hntQtSWjPk"
      },
      "source": [
        "And now let's see a few samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PM7R8ZZZHN7p",
        "outputId": "196aa2f4-66db-45ba-bf17-e8d8e207e99f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x coordinate (row): 0\n",
            "y coordinate (col): 2\n",
            "map:\n",
            "[[0. 0. 1. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "(theta,rho),maps = next(gen)\n",
        "for i,map in enumerate(maps):\n",
        "  #let us compute the cartesian coordinates\n",
        "  x = np.cos(theta[i])*rho[i]\n",
        "  y = np.sin(theta[i])*rho[i]\n",
        "  print(\"x coordinate (row): {}\".format(int(x*g1)))\n",
        "  print(\"y coordinate (col): {}\".format(int(y*g2)))\n",
        "  print(\"map:\")\n",
        "  print(np.reshape(map,(g1,g2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTY5fu8Hg7RE"
      },
      "source": [
        "Exercise: add noise to the generator, and check the effect on the \"ground truth\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jj4akvA24maJ"
      },
      "source": [
        "## What to deliver\n",
        "\n",
        "For the purposes of the project you are supposed to work with the **default 10x10 grid, and the default noise=.002**\n",
        "\n",
        "The generator must be treatead as a black box, do not tweak it, and do not exploit its semantics that is supposed to be unknown. You are allowed to work with the \"flat\" modality, if you prefer so.\n",
        "\n",
        "You need to:\n",
        "1.   define an accuracy function (take inspiration from the code of the previous cell)\n",
        "2.   define a neural network taking in input theta and rho, and returning out\n",
        "3. measure the network's accuracy that must be above 95% (accuracy must be evaluated over at least 20000 samples)\n",
        "4. tune the network trying to decrease as much as possible the numer of parameters, preserving an accuracy above 95%. Only your best network must be delivered.\n",
        "\n",
        "You must deliver a SINGLE notebook working on colab, containing the code of the network, its summary, the training history, the code for the accurary metric and its evaluation on the network.\n",
        "\n",
        "**N.B.** The accuracy must be above 95% but apart from that it does not influence the evaluation. You score will only depend on the number of parameters: the lower, the better.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQDSUJc1YGtr"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "aKUHeaC-3hxM"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Concatenate, Dense,  BatchNormalization, Conv2D, UpSampling2D\n",
        "from keras.activations import leaky_relu\n",
        "import keras.backend as K\n",
        "batch_size=6500\n",
        "\n",
        "def create_model():\n",
        "    # Define the input layers\n",
        "    theta_input = Input(shape=(1,), name='theta_input')\n",
        "    rho_input = Input(shape=(1,), name='rho_input')\n",
        "    # Concatenate the inputs\n",
        "    concatenated = Concatenate()([theta_input, rho_input])\n",
        "\n",
        "    # HIDDEN LAYERS\n",
        "    hidden=Dense(6,  activation=\"selu\")(concatenated)\n",
        "    hidden=Dense(6,  activation=\"selu\")(hidden)\n",
        "    hidden=Dense(2,  activation=\"selu\")(hidden)\n",
        "\n",
        "    output=Dense(100,  activation=\"softmax\")(hidden)\n",
        "\n",
        "\n",
        "\n",
        "    # Define the model and return it\n",
        "    model = Model(inputs=[theta_input, rho_input], outputs=output)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "POdmHLtZpWQU"
      },
      "outputs": [],
      "source": [
        "def one_hot_accuracy(y_true, y_pred):\n",
        "  # Convert the predictions to one_hot vectors\n",
        "  y_pred_one_hot = K.one_hot(K.argmax(y_pred, axis=1), K.shape(y_pred)[1])\n",
        "  # Compare the predictions with the true labels and count the matches\n",
        "  correct = K.cast(K.equal(y_true, y_pred_one_hot), K.floatx())\n",
        "  matches = K.sum(correct, axis=-1)\n",
        "  # Divide the matches by the number of classes to get the accuracy\n",
        "  accuracy = matches / K.cast(K.shape(y_pred)[1], K.floatx())\n",
        "  return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVe2v3yx3hxP",
        "outputId": "e82e36b3-df58-416a-89e4-30026ec74a90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " theta_input (InputLayer)       [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " rho_input (InputLayer)         [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate)    (None, 2)            0           ['theta_input[0][0]',            \n",
            "                                                                  'rho_input[0][0]']              \n",
            "                                                                                                  \n",
            " dense_24 (Dense)               (None, 6)            18          ['concatenate_6[0][0]']          \n",
            "                                                                                                  \n",
            " dense_25 (Dense)               (None, 6)            42          ['dense_24[0][0]']               \n",
            "                                                                                                  \n",
            " dense_26 (Dense)               (None, 2)            14          ['dense_25[0][0]']               \n",
            "                                                                                                  \n",
            " dense_27 (Dense)               (None, 100)          300         ['dense_26[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 374\n",
            "Trainable params: 374\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model=create_model()\n",
        "# from tensorflow import keras\n",
        "opt = keras.optimizers.Adamax(learning_rate=0.1)\n",
        "model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"categorical_accuracy\"])\n",
        "model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "pZr6OJuG610k"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "# Define the EarlyStopping callback\n",
        "early_stop = EarlyStopping(monitor='val_categorical_accuracy', patience=25, verbose=1, mode='max', restore_best_weights=True)\n",
        "\n",
        "# Define the ReduceLROnPlateau callback\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.1, patience=5, verbose=1, mode='max', min_lr=1e-5)\n",
        "\n",
        "# Define the ModelCheckpoint callback\n",
        "checkpoint = ModelCheckpoint('polar_express.h5', monitor='val_categorical_accuracy', save_best_only=True, mode='max', verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 797
        },
        "id": "eAHxOMFL3hxQ",
        "outputId": "6c1bc30c-aaac-4ab1-cfe6-4ad406a563c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "2000/2000 [==============================] - 15s 6ms/step - loss: 1.9046 - categorical_accuracy: 0.4070 - val_loss: 1.2172 - val_categorical_accuracy: 0.6257 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "2000/2000 [==============================] - 13s 7ms/step - loss: 1.0542 - categorical_accuracy: 0.6574 - val_loss: 0.9001 - val_categorical_accuracy: 0.7107 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "2000/2000 [==============================] - 13s 6ms/step - loss: 0.8146 - categorical_accuracy: 0.7292 - val_loss: 0.7990 - val_categorical_accuracy: 0.7041 - lr: 0.1000\n",
            "Epoch 4/200\n",
            "2000/2000 [==============================] - 13s 6ms/step - loss: 0.6913 - categorical_accuracy: 0.7680 - val_loss: 0.7115 - val_categorical_accuracy: 0.7369 - lr: 0.1000\n",
            "Epoch 5/200\n",
            "2000/2000 [==============================] - 13s 6ms/step - loss: 0.6027 - categorical_accuracy: 0.7911 - val_loss: 0.6326 - val_categorical_accuracy: 0.7836 - lr: 0.1000\n",
            "Epoch 6/200\n",
            "2000/2000 [==============================] - 13s 7ms/step - loss: 0.5272 - categorical_accuracy: 0.8177 - val_loss: 0.4816 - val_categorical_accuracy: 0.8347 - lr: 0.1000\n",
            "Epoch 7/200\n",
            "2000/2000 [==============================] - 13s 6ms/step - loss: 0.4890 - categorical_accuracy: 0.8291 - val_loss: 0.4788 - val_categorical_accuracy: 0.8216 - lr: 0.1000\n",
            "Epoch 8/200\n",
            "2000/2000 [==============================] - 13s 6ms/step - loss: 0.4629 - categorical_accuracy: 0.8360 - val_loss: 0.4143 - val_categorical_accuracy: 0.8673 - lr: 0.1000\n",
            "Epoch 9/200\n",
            "2000/2000 [==============================] - 13s 6ms/step - loss: 0.4394 - categorical_accuracy: 0.8435 - val_loss: 0.4824 - val_categorical_accuracy: 0.8123 - lr: 0.1000\n",
            "Epoch 10/200\n",
            "2000/2000 [==============================] - 13s 6ms/step - loss: 0.4200 - categorical_accuracy: 0.8504 - val_loss: 0.4641 - val_categorical_accuracy: 0.8125 - lr: 0.1000\n",
            "Epoch 11/200\n",
            "2000/2000 [==============================] - 13s 6ms/step - loss: 0.4059 - categorical_accuracy: 0.8545 - val_loss: 0.3767 - val_categorical_accuracy: 0.8692 - lr: 0.1000\n",
            "Epoch 12/200\n",
            "2000/2000 [==============================] - 13s 6ms/step - loss: 0.3957 - categorical_accuracy: 0.8567 - val_loss: 0.3853 - val_categorical_accuracy: 0.8579 - lr: 0.1000\n",
            "Epoch 13/200\n",
            "1487/2000 [=====================>........] - ETA: 3s - loss: 0.3848 - categorical_accuracy: 0.8608"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-f95f18d8f0a0>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mval_gen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpolar_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Train the model using the generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "batch_size=2048\n",
        "# Define the generator instance\n",
        "train_gen = polar_generator(batchsize=batch_size, flat=True)\n",
        "val_gen=polar_generator(batchsize=batch_size, flat=True)\n",
        "# Train the model using the generator\n",
        "history=model.fit(train_gen, steps_per_epoch=2000, epochs=200, callbacks=[early_stop, reduce_lr, checkpoint], validation_data=val_gen, validation_steps=250, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpQRWRX591Fd"
      },
      "outputs": [],
      "source": [
        "gen=polar_generator(batchsize=20000, flat=True)\n",
        "data=next(gen)\n",
        "pred=model.predict(data[0], verbose=False)\n",
        "acc=one_hot_accuracy(data[1], pred)\n",
        "print(\"accuracy:\", np.mean(acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axgo071W6U12"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "# Plot the training loss\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "# Plot the training accuracy\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.history['val_categorical_accuracy'])\n",
        "plt.plot(history.history['categorical_accuracy'])\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}